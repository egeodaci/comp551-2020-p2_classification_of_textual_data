/home/ramon/virtual_envs/comp551_p2/bin/python /home/ramon/github/comp551-2020-p2_classification_of_textual_data/code/main.py --all_categories --report --confusion_matrix --filtered --plot_training_and_test_time_together_with_accuracy_score

####################################
# Classification of text documents
####################################

This code uses many machine learning approaches to classify documents by topics using a bag-of-words approach.

The datasets used in this are the 20 newsgroups dataset (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) and the IMDB Reviews dataset (http://ai.stanford.edu/~amaas/data/sentiment/).

Usage: main.py [options]

Options:
  -h, --help            show this help message and exit
  --report              Print a detailed classification report.
  --chi2_select=SELECT_CHI2
                        Select some number of features using a chi-squared
                        test
  --confusion_matrix    Print the confusion matrix.
  --top10               Print ten most discriminative terms per class for
                        every classifier.
  --all_categories      Whether to use all categories or not.
  --use_hashing         Use a hashing vectorizer.
  --n_features=N_FEATURES
                        n_features when using the hashing vectorizer.
  --filtered            Remove newsgroup information that is easily overfit:
                        headers, signatures, and quoting.
  --just_miniproject_classifiers
                        Use just the miniproject classifiers (1.
                        LogisticRegression, 2. DecisionTreeClassifier, 3.
                        LinearSVC (L1), 4. LinearSVC (L2), 5.
                        AdaBoostClassifier, 6. RandomForestClassifier)
  --plot_training_and_test_time_together_with_accuracy_score
                        Plot training time and test time together with
                        accuracy score

Loading 20 newsgroups dataset for categories:
all
data loaded
11314 documents - 13.782MB (training set)
7532 documents - 8.262MB (test set)
20 categories

Extracting features from the training data using a sparse vectorizer
done in 1.996919s at 6.902MB/s
n_samples: 11314, n_features: 101322

Extracting features from the test data using the same vectorizer
done in 1.061311s at 7.784MB/s
n_samples: 7532, n_features: 101322

================================================================================
Ridge Classifier
________________________________________________________________________________
Training: 
RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize=False, random_state=None, solver='sag',
                tol=0.01)
/home/ramon/virtual_envs/comp551_p2/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:558: UserWarning: "sag" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to "auto" or "sparse_cg", or set a low "tol" and a high "max_iter" (especially if inputs are not standardized).
  '"sag" solver requires many iterations to fit '
train time: 4.832s
test time:  0.029s
accuracy:   0.703
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.56      0.49      0.52       319
           comp.graphics       0.68      0.74      0.71       389
 comp.os.ms-windows.misc       0.65      0.65      0.65       394
comp.sys.ibm.pc.hardware       0.67      0.68      0.67       392
   comp.sys.mac.hardware       0.73      0.70      0.72       385
          comp.windows.x       0.83      0.71      0.77       395
            misc.forsale       0.75      0.79      0.77       390
               rec.autos       0.76      0.72      0.74       396
         rec.motorcycles       0.81      0.77      0.79       398
      rec.sport.baseball       0.54      0.85      0.66       397
        rec.sport.hockey       0.88      0.88      0.88       399
               sci.crypt       0.85      0.71      0.78       396
         sci.electronics       0.62      0.60      0.61       393
                 sci.med       0.79      0.79      0.79       396
               sci.space       0.75      0.75      0.75       394
  soc.religion.christian       0.64      0.82      0.72       398
      talk.politics.guns       0.60      0.68      0.64       364
   talk.politics.mideast       0.85      0.76      0.80       376
      talk.politics.misc       0.58      0.47      0.52       310
      talk.religion.misc       0.45      0.25      0.32       251

                accuracy                           0.70      7532
               macro avg       0.70      0.69      0.69      7532
            weighted avg       0.71      0.70      0.70      7532

confusion matrix:
[[156   1   4   1   1   0   8   3   0  13   3   1   7   6  11  54   7  11
    7  25]
 [  2 287  20   8   7  19   6   2   1   8   0   7  10   0   7   2   1   1
    0   1]
 [  2  20 257  32  14  12   4   3   1  17   2   3   2   6   8   1   0   2
    6   2]
 [  0  10  33 268  26   6  10   1   0   9   2   3  21   0   1   1   0   0
    1   0]
 [  2   8   8  29 271   4  12   6   1  15   1   3  15   2   2   2   3   0
    0   1]
 [  1  44  36   7   5 280   2   0   1   9   0   1   2   0   4   0   2   0
    0   1]
 [  0   2   3  14  16   0 307   8   5  11   1   1   9   3   2   2   2   1
    2   1]
 [  3   1   3   1   3   1  14 284  14  28   2   2  19   3   4   1   3   4
    5   1]
 [  5   3   0   2   2   0   7  15 306  18   3   0   8   6   7   3   3   1
    7   2]
 [  1   2   0   1   0   1   5   4   5 339  19   1   1   4   1   4   1   2
    6   0]
 [  1   1   3   0   1   0   0   2   2  25 350   0   2   4   0   0   5   0
    1   2]
 [  2   5   6   4   6   0   6   4   3  20   1 283  11   2   5   5  17   2
   12   2]
 [  4  12  10  28  12   6  15  12   7  15   4  11 234   8   8   3   1   1
    2   0]
 [  4   6   2   0   1   1   2   5   5  15   6   0   7 311   6   6   6   5
    6   2]
 [  7  10   2   2   2   1   3   8   6  20   3   1  12   8 297   1   2   0
    7   2]
 [ 19   2   4   0   0   1   1   0   2  15   0   1   3   5   4 325   0   2
    3  11]
 [  6   2   3   1   1   1   4   7   7  13   1   7   1   8   9   7 249   7
   19  11]
 [ 25   1   1   2   0   0   2   2   5  11   0   2   2   2   4   8   7 286
   14   2]
 [  9   0   0   0   2   1   1   4   4  12   2   3   6   8  10   3  85   5
  146   9]
 [ 30   5   2   3   1   2   2   2   2  11   0   1   4   8   6  76  19   6
    9  62]]

================================================================================
Perceptron
________________________________________________________________________________
Training: 
Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,
           fit_intercept=True, max_iter=50, n_iter_no_change=5, n_jobs=None,
           penalty=None, random_state=0, shuffle=True, tol=0.001,
           validation_fraction=0.1, verbose=0, warm_start=False)
train time: 1.223s
test time:  0.036s
accuracy:   0.634
dimensionality: 101322
density: 0.118555

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.49      0.45      0.46       319
           comp.graphics       0.65      0.66      0.66       389
 comp.os.ms-windows.misc       0.53      0.56      0.55       394
comp.sys.ibm.pc.hardware       0.59      0.60      0.59       392
   comp.sys.mac.hardware       0.66      0.68      0.67       385
          comp.windows.x       0.69      0.65      0.67       395
            misc.forsale       0.72      0.74      0.73       390
               rec.autos       0.70      0.66      0.68       396
         rec.motorcycles       0.75      0.66      0.70       398
      rec.sport.baseball       0.50      0.76      0.60       397
        rec.sport.hockey       0.77      0.82      0.80       399
               sci.crypt       0.77      0.67      0.72       396
         sci.electronics       0.61      0.50      0.55       393
                 sci.med       0.80      0.66      0.73       396
               sci.space       0.73      0.66      0.70       394
  soc.religion.christian       0.63      0.72      0.67       398
      talk.politics.guns       0.51      0.59      0.55       364
   talk.politics.mideast       0.77      0.72      0.75       376
      talk.politics.misc       0.43      0.41      0.42       310
      talk.religion.misc       0.33      0.31      0.32       251

                accuracy                           0.63      7532
               macro avg       0.63      0.62      0.63      7532
            weighted avg       0.64      0.63      0.63      7532

confusion matrix:
[[142   4   2   1   4   3   5   2   5  13  10   1   5   4   4  48  16   8
   10  32]
 [  3 257  22   5  14  23   6   5   0  13   3  11   8   3   6   2   0   1
    3   4]
 [  5  19 221  36  16  29   4   6   3  16   3   3   4   4   8   1   2   4
    7   3]
 [  1  14  36 236  29   9  13   3   1   7   2   5  16   2   3   2   3   0
    7   3]
 [  1   6  11  26 260   7   8   5   2  17   5   4  11   2   3   3   7   1
    5   1]
 [  3  38  36   5   9 258   7   1   1   8   3   5   4   0   6   2   3   2
    3   1]
 [  0   3   7  16  16   3 287  12   3  11   3   1   6   1   4   4   6   1
    2   4]
 [  3   1   7   9   6   1  11 260  12  29   5   2  15   0   2   2   9   8
    9   5]
 [  7   6   6   4   2   5   6  20 262  23   4   0  10   4   6   3   7   5
   12   6]
 [  8   2   3   3   0   2   4   3   9 301  18   1   4   8   4   6   5   0
   14   2]
 [  2   3   3   2   2   1   1   2   3  23 328   2   2   2   2   6   6   4
    1   4]
 [  1   6  10   9   6   3   6   5   7  20   7 266   9   2  10   3  10   3
   10   3]
 [  7  12  16  24  17   9  16  14  12  17   6   8 195   8   8   2   6   3
   12   1]
 [  7   8   7   5   1   5   3  12   6  20   7   1   5 263   2   9  10   7
   12   6]
 [  7   9   8   4   3   5   3   8   2  21   9   4  16   5 262   4  10   3
    6   5]
 [ 22   0   3   3   2   3   5   1   4  16   1   3   0   2   3 288   2   2
    4  34]
 [  9   1   7   7   1   3   2   4   7  15   3  12   4   5   5  12 215   7
   25  20]
 [ 22   1   3   3   0   2   4   2   4  11   2   3   2   2   3   9   8 272
   19   4]
 [ 13   0   1   3   4   1   4   3   5  14   3   8   2   5   9   6  74  11
  127  17]
 [ 29   3   6   2   4   3   2   2   2  10   3   5   4   6   8  46  21  10
    7  78]]

================================================================================
Passive-Aggressive
________________________________________________________________________________
Training: 
PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,
                            early_stopping=False, fit_intercept=True,
                            loss='hinge', max_iter=50, n_iter_no_change=5,
                            n_jobs=None, random_state=None, shuffle=True,
                            tol=0.001, validation_fraction=0.1, verbose=0,
                            warm_start=False)
train time: 1.802s
test time:  0.029s
accuracy:   0.684
dimensionality: 101322
density: 0.422010

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.49      0.46      0.48       319
           comp.graphics       0.64      0.70      0.67       389
 comp.os.ms-windows.misc       0.64      0.59      0.62       394
comp.sys.ibm.pc.hardware       0.62      0.64      0.63       392
   comp.sys.mac.hardware       0.71      0.69      0.70       385
          comp.windows.x       0.82      0.71      0.76       395
            misc.forsale       0.76      0.78      0.77       390
               rec.autos       0.77      0.72      0.75       396
         rec.motorcycles       0.49      0.78      0.60       398
      rec.sport.baseball       0.86      0.80      0.83       397
        rec.sport.hockey       0.86      0.86      0.86       399
               sci.crypt       0.81      0.72      0.76       396
         sci.electronics       0.65      0.57      0.61       393
                 sci.med       0.78      0.75      0.76       396
               sci.space       0.73      0.74      0.74       394
  soc.religion.christian       0.64      0.75      0.69       398
      talk.politics.guns       0.59      0.64      0.61       364
   talk.politics.mideast       0.83      0.76      0.79       376
      talk.politics.misc       0.54      0.46      0.50       310
      talk.religion.misc       0.41      0.33      0.37       251

                accuracy                           0.68      7532
               macro avg       0.68      0.67      0.67      7532
            weighted avg       0.69      0.68      0.68      7532

confusion matrix:
[[148   1   4   1   3   0   2   3  17   1   4   6   5   6   9  49   8  11
    9  32]
 [  4 273  20   8   9  21   6   3   8   2   0   9   5   4   8   3   1   2
    1   2]
 [  4  24 234  42  13  14   4   2  17   1   1   3   2   4  11   2   3   3
    8   2]
 [  1  15  34 250  24   6  15   0   7   3   2   5  22   1   2   0   0   1
    3   1]
 [  2  13   6  27 265   3  13   7  16   2   3   3  15   1   1   2   5   1
    0   0]
 [  2  43  32   4   3 279   5   1   7   1   0   5   3   1   3   0   3   1
    0   2]
 [  2   3   2  13  16   1 306   9  13   2   1   1  10   1   1   1   2   3
    2   1]
 [  4   2   1   3   5   3  11 286  38   3   2   1  14   3   7   1   3   5
    4   0]
 [  5   5   2   1   4   2   5  14 309   6   3   1   8   4   6   3   6   2
    9   3]
 [  2   2   0   1   1   1   4   5  22 319  18   0   2   3   4   5   1   1
    6   0]
 [  1   0   1   0   3   0   0   1  16  14 345   0   1   3   0   3   5   0
    1   5]
 [  5   6   4   7   3   5   5   3  21   0   2 284   5   3   8   3  11   2
   13   6]
 [  4  12  12  25  15   4  15   8  21   5   4  13 224  11  11   2   1   1
    5   0]
 [  5   4   2   2   1   0   1   7  22   1   6   0   8 298   8  10   7   5
    5   4]
 [  8  13   3   3   2   1   3   9  22   1   4   0   9   7 293   3   4   1
    6   2]
 [ 24   1   3   3   1   1   3   0  16   0   0   1   2   4   5 299   0   1
    4  30]
 [  8   3   3   2   1   0   4   5  18   1   0  11   1  10   7  11 232   8
   24  15]
 [ 28   1   1   2   0   0   1   2  13   4   2   0   1   3   1  11   5 284
   13   4]
 [ 14   0   0   3   0   0   0   3  12   4   2   2   3  11   8   2  82   8
  142  14]
 [ 30   6   2   4   2   1   1   2  11   2   1   5   4   6   6  59  14   3
    8  84]]

================================================================================
kNN
________________________________________________________________________________
Training: 
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,
                     weights='uniform')
train time: 0.004s
test time:  3.578s
accuracy:   0.064
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.05      0.08      0.06       319
           comp.graphics       0.04      0.09      0.06       389
 comp.os.ms-windows.misc       0.06      0.18      0.09       394
comp.sys.ibm.pc.hardware       0.09      0.05      0.07       392
   comp.sys.mac.hardware       0.05      0.09      0.06       385
          comp.windows.x       0.29      0.01      0.02       395
            misc.forsale       0.19      0.06      0.09       390
               rec.autos       0.06      0.17      0.09       396
         rec.motorcycles       0.09      0.07      0.08       398
      rec.sport.baseball       0.07      0.12      0.08       397
        rec.sport.hockey       0.10      0.06      0.07       399
               sci.crypt       0.06      0.04      0.05       396
         sci.electronics       0.06      0.04      0.05       393
                 sci.med       0.05      0.03      0.04       396
               sci.space       0.11      0.05      0.06       394
  soc.religion.christian       0.11      0.02      0.03       398
      talk.politics.guns       0.03      0.01      0.02       364
   talk.politics.mideast       0.11      0.07      0.08       376
      talk.politics.misc       0.02      0.01      0.01       310
      talk.religion.misc       0.03      0.02      0.02       251

                accuracy                           0.06      7532
               macro avg       0.08      0.06      0.06      7532
            weighted avg       0.09      0.06      0.06      7532

confusion matrix:
[[26 34 42 13 29  0  5 51  5 33 11 11  9 12  6  2  3  9 12  6]
 [29 36 71 16 27  0  5 48 19 41 11 13  9  8 10  3  9 21  4  9]
 [26 41 72 12 40  1  5 58 14 32 15  8 13 14 14  1  5  9  8  6]
 [29 33 62 21 46  1  5 51 13 30 13 15 10 10  8  5 10 13  9  8]
 [36 43 45 10 35  0  2 69 16 29 14  7 16 14  3  3  8 16 11  8]
 [29 47 68  5 35  4  3 61 25 29  9 14 10 13  6  4  7 12  5  9]
 [25 40 57 19 38  2 22 52 15 30 15 13 14  9  8  1  3 11  5 11]
 [24 53 62 14 52  1  4 68 11 27 19  9  9  6  7  2  3  8  9  8]
 [32 38 49 15 32  2  8 58 27 37  7 13 15 11  8  1 10 16 10  9]
 [35 43 73 18 33  0  4 66 13 46  6  7  8 10  7  3  5  6  5  9]
 [29 47 61 12 39  0  2 55 13 37 23 12  7 12  8  3 10 11 12  6]
 [29 49 52  6 37  0  6 68 16 38 13 14 14 13  6  3  7 11  5  9]
 [21 36 58 15 33  0  7 67 14 38 14 12 14 20  6  2  6 10  9 11]
 [29 46 59 10 41  1  6 55 15 45 10 13 13 12  7  3 11 10  5  5]
 [30 40 61 11 27  0  9 68 13 31 10  9 12 14 18  1 11 10  7 12]
 [31 44 55 16 40  1  7 60 12 37  8 15 11 11  9  6  8  8 12  7]
 [27 42 64  6 33  0  4 57 16 44  9 12  8 11  8  1  4 11  4  3]
 [25 35 57 10 33  0  3 63 11 37  7  7  9  7 10  9  5 26  9 13]
 [14 32 51 14 35  1  2 43  9 28  8 10 15  7 10  3 11 10  3  4]
 [17 28 42  4 25  0  4 40 12 18  9  6  9  7  2  1  3 16  4  4]]

================================================================================
Logistic Regression
________________________________________________________________________________
Training: 
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
train time: 46.840s
test time:  0.028s
accuracy:   0.695
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.48      0.46      0.47       319
           comp.graphics       0.64      0.71      0.67       389
 comp.os.ms-windows.misc       0.66      0.63      0.64       394
comp.sys.ibm.pc.hardware       0.68      0.65      0.66       392
   comp.sys.mac.hardware       0.76      0.69      0.72       385
          comp.windows.x       0.84      0.72      0.78       395
            misc.forsale       0.77      0.78      0.78       390
               rec.autos       0.75      0.73      0.74       396
         rec.motorcycles       0.48      0.81      0.61       398
      rec.sport.baseball       0.81      0.83      0.82       397
        rec.sport.hockey       0.92      0.87      0.89       399
               sci.crypt       0.89      0.68      0.77       396
         sci.electronics       0.57      0.62      0.59       393
                 sci.med       0.78      0.79      0.79       396
               sci.space       0.71      0.75      0.73       394
  soc.religion.christian       0.65      0.82      0.72       398
      talk.politics.guns       0.58      0.68      0.63       364
   talk.politics.mideast       0.85      0.76      0.80       376
      talk.politics.misc       0.61      0.44      0.51       310
      talk.religion.misc       0.57      0.18      0.27       251

                accuracy                           0.69      7532
               macro avg       0.70      0.68      0.68      7532
            weighted avg       0.71      0.69      0.69      7532

confusion matrix:
[[146   2   3   1   1   2   1   5  19   6   1   1   3  10  17  66   6  12
    6  11]
 [  5 278  22   7   6  19   7   2  10   4   0   4  14   1   9   1   0   0
    0   0]
 [  4  21 247  39  14  13   2   3  19   2   1   3   2   8  10   0   2   0
    3   1]
 [  1  14  35 255  26   3  11   2   8   1   1   1  33   0   1   0   0   0
    0   0]
 [  2   7  10  27 266   3  13   2  16   2   1   1  26   4   4   1   0   0
    0   0]
 [  0  45  28   8   3 286   1   2   9   1   0   2   3   2   4   0   0   0
    1   0]
 [  0   2   2  15  15   0 306  10  13   2   1   1  13   2   3   1   3   0
    1   0]
 [  1   0   1   0   2   1  11 288  43   6   0   0  21   1   9   1   4   2
    4   1]
 [  5   2   0   0   1   0   7  19 323   6   0   0  12   4   7   2   3   0
    7   0]
 [  2   4   0   1   0   2   3   3  23 329  16   0   2   3   0   3   0   3
    3   0]
 [  4   2   0   0   1   0   0   3  14  17 346   0   1   2   0   0   6   1
    2   0]
 [  3  11   5   3   5   3   4   2  24   4   1 271  13   6   7   1  20   4
    9   0]
 [  4  19  12  19  10   2  14  12  19   5   0  12 242   8   9   2   1   2
    1   0]
 [  7   7   1   1   0   2   6   6  23   0   2   0   8 314   4   5   3   1
    5   1]
 [  6  11   2   0   1   1   4   7  23   3   2   0  13  11 295   2   5   2
    6   0]
 [ 19   3   3   0   0   0   1   0  20   3   0   0   2   3   5 326   2   3
    2   6]
 [ 10   1   2   0   1   1   2   7  22   3   1   7   3   5   9   8 249   6
   19   8]
 [ 24   2   2   0   0   0   1   3  15   6   0   2   4   2   2   7   8 284
   13   1]
 [ 16   1   0   0   0   1   2   2  13   3   2   1   4   7  12   2  94   9
  137   4]
 [ 43   3   2   0   0   1   1   4  12   3   2   0   3  10   8  76  25   7
    7  44]]

================================================================================
Decision Tree Classifier
________________________________________________________________________________
Training: 
DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=None, splitter='best')
train time: 21.531s
test time:  0.014s
accuracy:   0.438
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.28      0.27      0.28       319
           comp.graphics       0.45      0.43      0.44       389
 comp.os.ms-windows.misc       0.45      0.46      0.45       394
comp.sys.ibm.pc.hardware       0.41      0.35      0.38       392
   comp.sys.mac.hardware       0.44      0.45      0.45       385
          comp.windows.x       0.50      0.44      0.47       395
            misc.forsale       0.56      0.58      0.57       390
               rec.autos       0.25      0.52      0.34       396
         rec.motorcycles       0.63      0.53      0.58       398
      rec.sport.baseball       0.54      0.51      0.52       397
        rec.sport.hockey       0.61      0.60      0.60       399
               sci.crypt       0.58      0.49      0.53       396
         sci.electronics       0.27      0.28      0.28       393
                 sci.med       0.46      0.41      0.43       396
               sci.space       0.50      0.47      0.49       394
  soc.religion.christian       0.48      0.52      0.50       398
      talk.politics.guns       0.39      0.40      0.39       364
   talk.politics.mideast       0.59      0.53      0.56       376
      talk.politics.misc       0.25      0.19      0.22       310
      talk.religion.misc       0.16      0.14      0.15       251

                accuracy                           0.44      7532
               macro avg       0.44      0.43      0.43      7532
            weighted avg       0.45      0.44      0.44      7532

confusion matrix:
[[ 86   7   2   0   6   1   5  27   7  11   7   4   6  13  12  49  12  13
   14  37]
 [  4 169  29  32  19  34   8  19   2   4   3  10  21   6  15   1   4   4
    3   2]
 [ 10  21 180  42  25  25   7  27   4   5   4   6  13   9   6   2   2   2
    2   2]
 [  5  25  36 139  36  21  20  22   8   1   2   7  40   7   6   3   3   4
    4   3]
 [  6  24  12  19 174  11  28  31   7   3   3  10  23  10   9   0   4   2
    7   2]
 [  3  32  48  23  18 174  10  26   3   1   2   6  15   9   8   1   4   7
    2   3]
 [  0  13   8  23  19   7 227  28   5   6  11   5  11   5   7   4   2   1
    6   2]
 [  8   6  14   5  16   6  23 204  18  10   2   4  22   9  12   5   8  13
    6   5]
 [  9   2   7   6  11   5  12  45 211  12   3   5  13   6  11   6  12   7
    4  11]
 [  7   2   4   6   4   1   5  39   6 201  66   6   4   8   6   4   6   8
    8   6]
 [  6   2   5   0   3   6   5  30   8  60 239   4   3   3   5   2   7   3
    2   6]
 [  7  16  12   6  13   5   5  42   4   1   3 194  14   8   4   6  32   7
    9   8]
 [  5  14  11  19  21  11  31  45  10  11   8  23 110  17  23   5   5  11
   11   2]
 [ 16  13   8   8  12  15   7  41   9   8   5   9  29 161  11   5   3  10
   16  10]
 [  9  11   4   5   6   6   4  41   6  10  11   8  29  17 186   8  13   5
   11   4]
 [ 36   3   3   2   4   5   2  23   1   8   4   2   9  10   6 205   3  13
   17  42]
 [ 15   5   7   2   4   5   4  39   6   4   5  16  15  13  18  18 144   6
   23  15]
 [ 27   0   2   0   1   5   2  21   5   9   2   6   7  10   5  14  19 198
   25  18]
 [ 19   3   4   1   1   5   1  27  10   5   8  10  17  18  11  15  70  13
   60  12]
 [ 27   4   4   3   2   1   3  27   3   4   6   2   3  10   8  74  17   9
    8  36]]

================================================================================
Linear SVC (penalty = L2)
________________________________________________________________________________
Training: 
LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.001,
          verbose=0)
train time: 6.595s
test time:  0.069s
accuracy:   0.697
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.54      0.49      0.51       319
           comp.graphics       0.66      0.72      0.69       389
 comp.os.ms-windows.misc       0.62      0.62      0.62       394
comp.sys.ibm.pc.hardware       0.65      0.66      0.66       392
   comp.sys.mac.hardware       0.73      0.70      0.72       385
          comp.windows.x       0.83      0.70      0.76       395
            misc.forsale       0.75      0.79      0.77       390
               rec.autos       0.75      0.71      0.73       396
         rec.motorcycles       0.79      0.76      0.77       398
      rec.sport.baseball       0.55      0.86      0.67       397
        rec.sport.hockey       0.87      0.87      0.87       399
               sci.crypt       0.83      0.72      0.77       396
         sci.electronics       0.63      0.59      0.61       393
                 sci.med       0.79      0.78      0.79       396
               sci.space       0.75      0.75      0.75       394
  soc.religion.christian       0.65      0.79      0.71       398
      talk.politics.guns       0.60      0.66      0.63       364
   talk.politics.mideast       0.84      0.76      0.80       376
      talk.politics.misc       0.55      0.46      0.50       310
      talk.religion.misc       0.45      0.29      0.35       251

                accuracy                           0.70      7532
               macro avg       0.69      0.68      0.68      7532
            weighted avg       0.70      0.70      0.69      7532

confusion matrix:
[[155   2   4   1   1   0   4   3   4  11   4   3   7   5   8  54   7  13
    9  24]
 [  4 279  20   9   6  21   6   2   0   9   0  11   8   2   8   2   1   0
    0   1]
 [  3  22 243  37  16  11   3   4   1  16   2   3   3   6   9   2   1   2
    8   2]
 [  0  10  38 260  26   6  12   1   0   9   2   4  21   0   1   0   0   0
    2   0]
 [  2  10   8  25 271   6  14   5   1  16   1   2  16   2   1   1   3   0
    0   1]
 [  1  41  39   5   4 278   2   1   1   9   0   2   3   1   5   0   2   0
    0   1]
 [  0   3   2  12  15   0 308   8   6  10   2   1   9   2   2   2   2   3
    2   1]
 [  2   1   3   3   3   1  13 283  17  26   3   2  16   3   5   2   4   4
    5   0]
 [  5   3   1   1   2   0   7  18 302  19   2   0   9   4   7   3   4   1
    8   2]
 [  1   2   0   2   0   1   6   3   5 340  17   0   2   4   1   4   1   2
    6   0]
 [  0   1   2   2   1   0   1   2   2  27 347   0   1   3   0   1   5   0
    1   3]
 [  5   6   5   4   4   1   6   2   4  19   1 285  10   3   5   4  12   2
   15   3]
 [  4  12   9  28  13   6  13  11   9  15   4  10 233   8   9   3   1   1
    3   1]
 [  5   6   4   1   1   0   1   9   4  15   5   0   7 309   6   5   5   5
    5   3]
 [  6  11   5   2   3   1   3  11   6  20   3   0   8   6 296   1   4   0
    6   2]
 [ 21   1   3   0   0   1   2   0   1  15   0   3   3   5   3 315   0   1
    5  19]
 [  8   3   3   1   1   0   4   7   7  13   0  10   1   9   7   9 242   8
   20  11]
 [ 25   1   1   2   0   0   2   2   7   9   1   1   2   3   3   8   8 284
   14   3]
 [  9   1   0   1   2   1   0   4   5  11   2   3   4   8  11   1  84   7
  144  12]
 [ 31   6   2   3   2   1   1   2   1  10   1   2   4   7   6  67  19   5
    8  73]]

================================================================================
Linear SVC (penalty = L1)
________________________________________________________________________________
Training: 
LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,
          verbose=0)
train time: 5.293s
test time:  0.022s
accuracy:   0.666
dimensionality: 101322
density: 0.005267

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.46      0.45      0.45       319
           comp.graphics       0.66      0.72      0.69       389
 comp.os.ms-windows.misc       0.64      0.63      0.63       394
comp.sys.ibm.pc.hardware       0.60      0.66      0.63       392
   comp.sys.mac.hardware       0.70      0.67      0.68       385
          comp.windows.x       0.82      0.66      0.73       395
            misc.forsale       0.72      0.75      0.74       390
               rec.autos       0.46      0.74      0.57       396
         rec.motorcycles       0.78      0.71      0.74       398
      rec.sport.baseball       0.83      0.74      0.78       397
        rec.sport.hockey       0.83      0.84      0.84       399
               sci.crypt       0.81      0.71      0.75       396
         sci.electronics       0.56      0.54      0.55       393
                 sci.med       0.79      0.72      0.76       396
               sci.space       0.75      0.71      0.73       394
  soc.religion.christian       0.62      0.76      0.68       398
      talk.politics.guns       0.57      0.66      0.61       364
   talk.politics.mideast       0.86      0.70      0.78       376
      talk.politics.misc       0.52      0.45      0.49       310
      talk.religion.misc       0.38      0.28      0.32       251

                accuracy                           0.67      7532
               macro avg       0.67      0.65      0.66      7532
            weighted avg       0.68      0.67      0.67      7532

confusion matrix:
[[142   2   3   2   1   0   6  16   7   2   4   3   6   7  11  61   8   7
    5  26]
 [  3 279  19  11   8  20   5   9   2   2   1   9   6   1   9   1   0   1
    1   2]
 [  6  19 247  40  11  12   2  18   1   1   2   4   3   5   6   4   4   0
    8   1]
 [  0  11  35 257  24   3   9   9   0   2   2   5  29   1   1   2   1   0
    0   1]
 [  2  12   7  27 258   4  10  16   5   2   3   2  22   5   4   3   2   0
    0   1]
 [  1  45  39   5   5 262   5   9   1   1   1   3   6   0   6   1   2   2
    0   1]
 [  0   1   3  22  16   0 294  19   1   3   2   1  11   2   5   1   5   1
    1   2]
 [  4   2   2   6   2   2  15 294  15   2   2   2  19   4   4   4   3   4
    9   1]
 [  5   2   2   2   2   1   6  43 284   6   1   2  13   4   5   4   3   0
    8   5]
 [  3   3   0   4   1   1   9  29   5 293  26   0   3   3   1   5   1   1
    5   4]
 [  1   2   3   2   5   1   0  12   4  18 334   1   2   1   1   3   3   0
    4   2]
 [  4   5   7   4   6   2  11  20   4   0   2 280  11   2   4   2  18   2
    9   3]
 [  5  11   5  34  18   4  15  27   6   6   6   9 213   8   7   5   7   1
    4   2]
 [  9  10   2   2   1   0   6  26   7   1   6   2   6 287   6   7   6   1
    8   3]
 [  6  11   3   4   4   2   3  24   6   3   1   2  16  10 279   4   2   0
   11   3]
 [ 25   2   1   0   2   1   1  15   3   1   0   4   3   4   2 301   3   6
    5  19]
 [  8   4   4   2   2   1   1  19   6   4   0   9   2   3   9   6 239   6
   23  16]
 [ 28   0   2   2   1   1   3   8   2   5   1   4   2   3   2  16  12 265
   16   3]
 [ 10   1   0   0   1   2   2  12   4   1   5   4   7   9   6   3  78   6
  140  19]
 [ 44   3   1   1   1   2   6  15   2   2   1   1   3   4   5  56  20   4
   10  70]]

================================================================================
SGD Classifier (penalty = L2)
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,
              random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 1.826s
test time:  0.030s
accuracy:   0.701
dimensionality: 101322
density: 0.317711

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.54      0.47      0.50       319
           comp.graphics       0.69      0.73      0.71       389
 comp.os.ms-windows.misc       0.63      0.64      0.64       394
comp.sys.ibm.pc.hardware       0.68      0.65      0.66       392
   comp.sys.mac.hardware       0.75      0.70      0.73       385
          comp.windows.x       0.80      0.72      0.76       395
            misc.forsale       0.76      0.80      0.78       390
               rec.autos       0.77      0.73      0.75       396
         rec.motorcycles       0.81      0.76      0.79       398
      rec.sport.baseball       0.83      0.81      0.82       397
        rec.sport.hockey       0.87      0.89      0.88       399
               sci.crypt       0.84      0.71      0.77       396
         sci.electronics       0.64      0.58      0.60       393
                 sci.med       0.51      0.84      0.63       396
               sci.space       0.75      0.76      0.76       394
  soc.religion.christian       0.64      0.81      0.71       398
      talk.politics.guns       0.59      0.67      0.63       364
   talk.politics.mideast       0.83      0.77      0.80       376
      talk.politics.misc       0.60      0.46      0.52       310
      talk.religion.misc       0.47      0.24      0.32       251

                accuracy                           0.70      7532
               macro avg       0.70      0.69      0.69      7532
            weighted avg       0.71      0.70      0.70      7532

confusion matrix:
[[151   2   2   1   1   2   5   3   1   5   6   3   7  16   9  58   7  13
    5  22]
 [  2 283  22   9   7  21   5   3   2   3   0   6   5   9   8   1   1   1
    0   1]
 [  3  20 253  30  13  13   6   3   0   1   1   3   0  22  10   3   2   2
    7   2]
 [  0  11  37 255  26   7  13   0   2   1   2   4  23   7   1   1   0   1
    1   0]
 [  2   6  10  25 271   7  13   3   1   1   1   5  14  16   2   4   3   0
    0   1]
 [  0  40  35   6   4 286   1   0   0   2   0   1   4   8   5   0   3   0
    0   0]
 [  0   2   2   9  14   0 312   8   3   3   1   1  11  11   4   3   2   1
    2   1]
 [  1   0   2   1   2   0  13 288  17   4   2   1  18  26   6   1   4   4
    4   2]
 [  4   3   1   1   1   0   4  21 303   5   3   0   9  19   8   4   3   0
    7   2]
 [  1   2   0   0   0   1   5   5   5 322  19   0   1  21   1   5   1   2
    6   0]
 [  0   0   2   1   1   0   0   1   2  13 354   0   1  13   1   3   6   0
    1   0]
 [  3   6   6   4   3   4   6   3   4   2   1 281  10  19   4   6  15   4
   12   3]
 [  5  11  11  27  11   7  14   9  10   6   4  12 226  22   9   3   1   1
    2   2]
 [  7   6   4   0   0   0   3   8   2   1   4   0   7 332   3   4   6   2
    5   2]
 [  7  10   3   0   1   0   3   7   2   3   2   1   8  29 301   2   3   3
    7   2]
 [ 22   2   3   0   0   1   2   0   2   2   1   1   2  19   3 324   0   2
    5   7]
 [  7   4   3   2   2   2   2   4   6   3   1  11   1  20   8   7 245  10
   13  13]
 [ 26   0   2   2   0   2   1   2   6   3   1   2   2   9   2   7   7 291
   10   1]
 [  9   0   0   1   2   2   0   4   3   5   3   3   4  18  11   3  84   7
  144   7]
 [ 31   4   3   3   0   2   1   3   1   2   2   1   2  19   7  71  22   8
    8  61]]

================================================================================
SGD Classifier (penalty = L1)
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,
              random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 2.061s
test time:  0.049s
accuracy:   0.700
dimensionality: 101322
density: 0.318237

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.53      0.48      0.50       319
           comp.graphics       0.68      0.73      0.71       389
 comp.os.ms-windows.misc       0.65      0.63      0.64       394
comp.sys.ibm.pc.hardware       0.66      0.66      0.66       392
   comp.sys.mac.hardware       0.75      0.70      0.72       385
          comp.windows.x       0.79      0.72      0.75       395
            misc.forsale       0.76      0.80      0.78       390
               rec.autos       0.78      0.72      0.75       396
         rec.motorcycles       0.52      0.79      0.63       398
      rec.sport.baseball       0.83      0.82      0.82       397
        rec.sport.hockey       0.86      0.89      0.87       399
               sci.crypt       0.84      0.71      0.77       396
         sci.electronics       0.62      0.58      0.60       393
                 sci.med       0.78      0.80      0.79       396
               sci.space       0.73      0.77      0.75       394
  soc.religion.christian       0.64      0.81      0.72       398
      talk.politics.guns       0.59      0.68      0.63       364
   talk.politics.mideast       0.83      0.77      0.80       376
      talk.politics.misc       0.57      0.46      0.51       310
      talk.religion.misc       0.49      0.24      0.32       251

                accuracy                           0.70      7532
               macro avg       0.70      0.69      0.69      7532
            weighted avg       0.70      0.70      0.70      7532

confusion matrix:
[[152   3   2   1   0   3   4   3  11   4   6   3   8   5  10  57   7  13
    6  21]
 [  3 285  20   9   7  20   5   2   7   3   0   7   6   2   9   1   1   1
    0   1]
 [  5  21 247  33  13  14   5   3  16   1   2   3   1   6   9   2   2   3
    7   1]
 [  0  12  34 259  26   6  13   0   8   1   2   4  22   0   1   1   0   1
    2   0]
 [  2   6   8  28 269   9  13   3  15   0   1   4  13   2   2   4   4   0
    1   1]
 [  0  42  33   6   5 285   1   0   7   1   0   2   4   1   6   0   2   0
    0   0]
 [  0   2   2  11  14   1 312   6  10   3   2   1  11   3   4   1   2   1
    3   1]
 [  1   0   1   1   4   0  13 286  40   4   3   1  20   1   6   1   4   4
    5   1]
 [  3   3   1   1   1   0   5  19 314   6   3   0  11   5   9   3   4   0
    8   2]
 [  1   2   0   0   0   1   5   5  22 324  18   0   1   3   1   5   1   2
    6   0]
 [  0   0   2   2   1   0   0   1  12  15 354   0   1   3   0   1   6   0
    1   0]
 [  2   5   5   4   3   4   6   4  21   2   1 282  11   3   4   6  15   3
   12   3]
 [  5  12  11  28  12   7  15   8  19   5   3  12 226  10  10   3   2   1
    2   2]
 [  6   5   4   0   0   0   2   5  18   1   6   0   7 315   6   5   5   4
    6   1]
 [  7  11   2   0   1   1   3   8  19   3   2   1   8   9 302   1   4   3
    8   1]
 [ 22   2   3   0   0   1   2   0  17   2   1   1   2   5   3 324   0   2
    4   7]
 [  7   3   3   2   2   2   3   4  17   5   1   8   1   8   8   7 246   8
   17  12]
 [ 28   0   1   2   0   2   2   2  12   2   1   2   3   3   2   6   7 290
   11   0]
 [ 11   0   0   1   1   2   0   3  10   5   3   3   4   9  14   3  85   5
  144   7]
 [ 32   5   2   4   0   2   1   3   8   2   2   1   3  11   6  72  22   8
    8  59]]

================================================================================
Ada Boost Classifier
________________________________________________________________________________
Training: 
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=None)
train time: 8.839s
test time:  0.496s
accuracy:   0.365
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.00      0.00      0.00       319
           comp.graphics       0.60      0.23      0.33       389
 comp.os.ms-windows.misc       0.64      0.40      0.49       394
comp.sys.ibm.pc.hardware       0.48      0.31      0.38       392
   comp.sys.mac.hardware       0.69      0.37      0.48       385
          comp.windows.x       0.73      0.41      0.52       395
            misc.forsale       0.75      0.52      0.61       390
               rec.autos       0.79      0.38      0.52       396
         rec.motorcycles       0.92      0.33      0.48       398
      rec.sport.baseball       0.74      0.19      0.30       397
        rec.sport.hockey       0.64      0.57      0.60       399
               sci.crypt       0.80      0.42      0.55       396
         sci.electronics       0.08      0.82      0.15       393
                 sci.med       0.88      0.21      0.34       396
               sci.space       0.73      0.34      0.46       394
  soc.religion.christian       0.52      0.65      0.58       398
      talk.politics.guns       0.48      0.24      0.32       364
   talk.politics.mideast       0.96      0.50      0.65       376
      talk.politics.misc       0.29      0.17      0.21       310
      talk.religion.misc       0.14      0.01      0.02       251

                accuracy                           0.37      7532
               macro avg       0.59      0.35      0.40      7532
            weighted avg       0.61      0.37      0.41      7532

confusion matrix:
[[  0   0   0   0   0   3   2   0   0   0   3   4 190   1   5  95   6   1
    6   3]
 [  0  90  16  12   7  23   4   1   0   0   3   2 224   0   7   0   0   0
    0   0]
 [  0  21 157  23  15  20   2   1   0   0   1   0 148   1   3   0   2   0
    0   0]
 [  0  12  27 121   8   3   5   0   0   0   1   2 207   2   4   0   0   0
    0   0]
 [  1   2   1  27 142   0  12   0   0   0   2   5 188   0   4   0   0   0
    1   0]
 [  0   9  32   4   3 162   2   0   0   0   0   4 170   0   4   0   0   1
    3   1]
 [  0   6   5  23   9   1 202  10   2   1   3   2 120   0   3   2   1   0
    0   0]
 [  0   0   2  10   0   0   8 152   4   0   1   1 206   0   1   1   9   0
    1   0]
 [  0   0   0  12   0   1   4   7 131   1   1   2 228   1   1   4   4   0
    1   0]
 [  0   1   0   3   0   0   3   0   0  75  92   1 215   0   1   1   2   0
    1   2]
 [  0   0   0   0   0   1   7   0   1  18 228   0 140   0   0   1   1   0
    1   1]
 [  0   0   0   2   6   1   1   0   1   0   0 168 167   0   3   1  16   2
   28   0]
 [  1   6   2  12   6   2   7  13   1   1   2  13 322   0   4   0   0   0
    1   0]
 [  3   0   0   0   1   0   2   0   0   0   0   0 293  84   0  10   1   0
    2   0]
 [  3   1   1   1   9   3   3   3   1   0   8   2 212   4 132   2   2   0
    7   0]
 [  4   1   0   0   0   0   1   0   0   0   0   0 122   0   1 257   0   2
    4   6]
 [  0   0   2   1   0   3   3   1   2   1   6   3 194   0   4  12  87   1
   43   1]
 [  1   0   0   0   0   0   0   0   0   1   0   1 138   0   1  15   9 187
   20   3]
 [  0   0   0   0   1   0   0   2   0   2   4   0 202   3   1   8  34   0
   52   1]
 [  1   0   1   1   0   0   1   3   0   1   1   1 136   0   1  84   9   1
    7   3]]

================================================================================
Random forest
________________________________________________________________________________
Training: 
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False)
train time: 80.313s
test time:  1.306s
accuracy:   0.627
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.44      0.37      0.40       319
           comp.graphics       0.56      0.60      0.58       389
 comp.os.ms-windows.misc       0.54      0.67      0.60       394
comp.sys.ibm.pc.hardware       0.63      0.58      0.61       392
   comp.sys.mac.hardware       0.67      0.65      0.66       385
          comp.windows.x       0.71      0.68      0.69       395
            misc.forsale       0.70      0.75      0.73       390
               rec.autos       0.42      0.69      0.52       396
         rec.motorcycles       0.72      0.69      0.70       398
      rec.sport.baseball       0.68      0.78      0.73       397
        rec.sport.hockey       0.84      0.80      0.82       399
               sci.crypt       0.78      0.66      0.71       396
         sci.electronics       0.51      0.44      0.47       393
                 sci.med       0.75      0.66      0.71       396
               sci.space       0.67      0.68      0.68       394
  soc.religion.christian       0.58      0.78      0.67       398
      talk.politics.guns       0.52      0.58      0.55       364
   talk.politics.mideast       0.82      0.70      0.76       376
      talk.politics.misc       0.53      0.35      0.42       310
      talk.religion.misc       0.39      0.10      0.15       251

                accuracy                           0.63      7532
               macro avg       0.62      0.61      0.61      7532
            weighted avg       0.63      0.63      0.62      7532

confusion matrix:
[[118   2   3   1   1   1   9  19   5   8   6   5   4   9  17  83   7   8
    5   8]
 [  1 235  37  11  10  36   7  10   2   7   2   3   6   2  15   0   1   0
    4   0]
 [  2  18 264  24  19  13   3  18   4   4   1   2   3   1   7   2   4   2
    2   1]
 [  1  16  55 227  22  11  10  12   1   3   2   1  28   1   2   0   0   0
    0   0]
 [  2  10  14  30 249   5  18  19   4   4   1   1  21   4   2   1   0   0
    0   0]
 [  2  40  42   6   6 267   4  11   1   3   0   2   1   1   6   1   1   0
    1   0]
 [  0   8   4  18  17   1 292  21   1   4   3   1   6   1   6   1   2   0
    4   0]
 [  4   7  11   1   3   5  13 275  27   2   1   2  18   3   6   2   9   3
    3   1]
 [  4   2   2   3   2   2  13  50 274  13   0   2   9   2   5   5   4   1
    3   2]
 [  3   6   4   1   1   1   1  24   8 311  21   1   3   3   1   2   1   1
    4   0]
 [  2   1   2   2   2   2   1  14   4  33 321   0   0   3   1   0   4   2
    4   1]
 [  5   8   9   3   6   5  10  19   2   2   3 262  16   3   7   0  23   6
    6   1]
 [  5  26  18  24  21   9  11  32   8  13   4  17 173  10  11   0   3   1
    6   1]
 [  8  17   6   0   2   3  13  25   6   9   2   0  13 263  14   6   1   5
    2   1]
 [  5  10   4   4   5   4   4  25   8  11   1   3  16   9 269   3   6   0
    7   0]
 [ 19   6   3   0   0   1   1  15   6   2   2   0   3   4   2 312   2   6
    7   7]
 [ 10   3   4   2   3   5   1  28   7   6   5  19   5   8   5  10 212   6
   16   9]
 [ 21   2   2   0   0   1   1   8   6  12   1   6   4   3   8  12  11 264
   13   1]
 [ 16   1   2   1   1   3   2  17   5   9   4   6   6  14   9   8  89   5
  107   5]
 [ 40   4   2   0   1   2   1  20   4   4   2   4   2   5   6  88  25  10
    7  24]]

================================================================================
SGDClassifier Elastic-Net penalty
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',
              power_t=0.5, random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 3.259s
test time:  0.024s
accuracy:   0.691
dimensionality: 101322
density: 0.033010

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.53      0.45      0.49       319
           comp.graphics       0.65      0.71      0.68       389
 comp.os.ms-windows.misc       0.64      0.63      0.64       394
comp.sys.ibm.pc.hardware       0.65      0.65      0.65       392
   comp.sys.mac.hardware       0.73      0.70      0.72       385
          comp.windows.x       0.80      0.71      0.75       395
            misc.forsale       0.76      0.79      0.77       390
               rec.autos       0.77      0.70      0.74       396
         rec.motorcycles       0.51      0.78      0.62       398
      rec.sport.baseball       0.80      0.83      0.81       397
        rec.sport.hockey       0.88      0.88      0.88       399
               sci.crypt       0.84      0.70      0.77       396
         sci.electronics       0.62      0.54      0.58       393
                 sci.med       0.76      0.80      0.78       396
               sci.space       0.71      0.78      0.74       394
  soc.religion.christian       0.62      0.83      0.71       398
      talk.politics.guns       0.55      0.67      0.60       364
   talk.politics.mideast       0.83      0.75      0.79       376
      talk.politics.misc       0.62      0.44      0.51       310
      talk.religion.misc       0.54      0.18      0.27       251

                accuracy                           0.69      7532
               macro avg       0.69      0.68      0.67      7532
            weighted avg       0.70      0.69      0.69      7532

confusion matrix:
[[144   2   2   2   1   1   5   6  11   2   6   3   6   7  19  66   7  12
    5  12]
 [  2 275  24  10   6  21   7   2   8   4   1   6   5   5   9   2   0   1
    0   1]
 [  5  20 248  31  14  14   2   4  15   3   1   3   1   8  13   2   5   0
    4   1]
 [  0  11  37 254  25   4  11   2   8   3   2   5  24   0   2   1   1   1
    1   0]
 [  2   8   9  24 271   7  10   2  16   3   0   2  16   4   4   1   4   0
    2   0]
 [  1  44  34   5   6 279   1   0   9   1   0   2   3   0   6   0   2   1
    0   1]
 [  0   3   1  13  13   1 310   7   9   3   1   1  10   3   6   1   4   1
    3   0]
 [  3   3   1   1   3   0  13 279  42   5   1   1  21   2   7   1   6   4
    2   1]
 [  1   3   1   3   1   0   5  23 312   8   2   0  10   6   9   3   3   1
    5   2]
 [  1   3   0   0   0   0   4   3  23 329  17   0   1   3   0   5   1   2
    5   0]
 [  0   1   2   1   1   0   0   1  14  15 352   0   0   3   0   2   6   0
    0   1]
 [  1   8   5   4   5   5   6   2  22   4   1 279  10   5   4   6  18   5
    4   2]
 [  6  15   9  32  14   6  17   9  18   6   4  14 211  11  13   3   2   1
    2   0]
 [  6   8   2   0   0   0   5   4  19   1   5   0   4 318   4   7   5   2
    5   1]
 [  5  11   2   2   1   1   4   5  20   6   2   0   6   8 307   2   4   2
    6   0]
 [ 20   2   1   0   1   1   1   0  16   3   0   1   2   5   4 331   1   2
    4   3]
 [  5   3   4   2   3   3   4   5  15   4   1  10   0   8   9  11 243   8
   17   9]
 [ 24   1   1   1   1   1   1   3   9   7   1   3   2   3   1   8  12 283
   13   1]
 [ 11   0   0   0   2   2   1   4  13   4   4   3   5   9  10   2  94   6
  136   4]
 [ 37   3   2   4   1   3   3   2   8   2   1   0   2  12   6  82  23   9
    6  45]]

================================================================================
NearestCentroid (aka Rocchio classifier)
________________________________________________________________________________
Training: 
NearestCentroid(metric='euclidean', shrink_threshold=None)
train time: 0.036s
test time:  0.026s
accuracy:   0.643
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.39      0.43      0.41       319
           comp.graphics       0.54      0.70      0.61       389
 comp.os.ms-windows.misc       0.68      0.60      0.64       394
comp.sys.ibm.pc.hardware       0.64      0.59      0.61       392
   comp.sys.mac.hardware       0.78      0.64      0.70       385
          comp.windows.x       0.87      0.64      0.73       395
            misc.forsale       0.82      0.73      0.77       390
               rec.autos       0.75      0.71      0.73       396
         rec.motorcycles       0.69      0.72      0.71       398
      rec.sport.baseball       0.88      0.78      0.83       397
        rec.sport.hockey       0.96      0.80      0.87       399
               sci.crypt       0.94      0.56      0.70       396
         sci.electronics       0.27      0.69      0.39       393
                 sci.med       0.92      0.57      0.70       396
               sci.space       0.75      0.71      0.73       394
  soc.religion.christian       0.68      0.67      0.67       398
      talk.politics.guns       0.58      0.63      0.61       364
   talk.politics.mideast       0.95      0.67      0.78       376
      talk.politics.misc       0.41      0.50      0.45       310
      talk.religion.misc       0.34      0.31      0.33       251

                accuracy                           0.64      7532
               macro avg       0.69      0.63      0.65      7532
            weighted avg       0.71      0.64      0.66      7532

confusion matrix:
[[137   5   0   0   0   1   0   2  10   3   0   1  30   0  14  53   7   4
    9  43]
 [  9 273  20   9   6  14   3   0   6   2   0   0  34   0   9   0   0   0
    3   1]
 [  7  33 237  32  14  10   0   3   3   1   0   1  30   1   8   0   1   0
    8   5]
 [  1  23  35 230  19   4   8   3   0   0   0   1  63   0   1   0   0   0
    3   1]
 [  1  12   9  32 245   1   8   2   3   1   1   0  60   2   3   0   1   0
    2   2]
 [  0  55  27   7   3 251   1   2   2   1   0   0  34   0   5   0   0   0
    6   1]
 [  1   4   3  24  11   1 286  12   3   1   0   1  36   0   3   1   0   0
    3   0]
 [  5   1   1   0   0   0   8 283  24   0   0   0  59   0   4   0   4   0
    5   2]
 [  7   0   0   1   0   0   6  30 288   4   0   0  35   2   3   2   5   0
   14   1]
 [  8   6   0   0   0   1   4   3   6 311  13   0  32   1   1   0   1   1
    8   1]
 [  7   1   0   0   0   0   0   2   8  19 321   0  23   2   2   0   3   0
    7   4]
 [  3  18   2   3   5   2   1   1   4   1   0 220  63   1   6   0  32   1
   25   8]
 [  3  24   9  22  10   1   8  10   6   2   0   7 273   4   7   1   1   0
    3   2]
 [ 11  25   0   0   0   0   8  10  14   1   0   0  71 224   4   5   1   1
   19   2]
 [  9  10   1   0   1   0   3   4   8   1   1   0  54   2 280   0   2   0
   18   0]
 [ 29   7   1   0   0   0   2   0   1   0   0   0  32   1   5 265   2   0
   10  43]
 [ 13   1   0   0   0   1   1   4  12   0   0   2  29   0   3   5 231   2
   41  19]
 [ 36   2   0   0   0   0   1   0  11   3   0   0  19   1   2   3   9 251
   28  10]
 [ 21   2   0   0   0   1   0   2   2   2   0   0  21   0   8   3  81   0
  156  11]
 [ 46   2   1   0   0   0   1   3   7   0   0   0  18   2   5  53  18   5
   11  79]]

================================================================================
Naive Bayes
________________________________________________________________________________
Training: 
MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)
train time: 0.125s
test time:  0.029s
accuracy:   0.696
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.56      0.43      0.49       319
           comp.graphics       0.65      0.71      0.68       389
 comp.os.ms-windows.misc       0.75      0.46      0.57       394
comp.sys.ibm.pc.hardware       0.59      0.72      0.65       392
   comp.sys.mac.hardware       0.71      0.69      0.70       385
          comp.windows.x       0.79      0.75      0.77       395
            misc.forsale       0.81      0.72      0.76       390
               rec.autos       0.76      0.72      0.74       396
         rec.motorcycles       0.76      0.73      0.74       398
      rec.sport.baseball       0.94      0.81      0.87       397
        rec.sport.hockey       0.59      0.93      0.72       399
               sci.crypt       0.72      0.76      0.74       396
         sci.electronics       0.74      0.60      0.66       393
                 sci.med       0.84      0.77      0.80       396
               sci.space       0.75      0.80      0.78       394
  soc.religion.christian       0.59      0.86      0.70       398
      talk.politics.guns       0.56      0.72      0.63       364
   talk.politics.mideast       0.81      0.80      0.80       376
      talk.politics.misc       0.56      0.44      0.49       310
      talk.religion.misc       0.47      0.21      0.29       251

                accuracy                           0.70      7532
               macro avg       0.70      0.68      0.68      7532
            weighted avg       0.70      0.70      0.69      7532

confusion matrix:
[[138   1   2   2   2   2   0   3   3   2  12   3   0   3  10  74  13  12
   12  25]
 [  2 278   6  17  15  24   6   0   5   3   6  13   2   0   9   2   0   1
    0   0]
 [  4  30 181  73  16  30   4   2   5   0  16  12   3   2   8   1   0   1
    3   3]
 [  0  13  20 284  29   4  10   2   0   0   8   5  16   0   0   0   0   0
    1   0]
 [  0  11   8  32 265   5   8   7   2   0  14   7  13   2   6   2   1   1
    1   0]
 [  0  46   9   9   7 297   1   0   0   1   7   5   5   3   4   0   1   0
    0   0]
 [  1   4   1  32  18   0 281  14   7   3  11   1   7   2   4   1   1   0
    2   0]
 [  1   1   1   1   1   0   9 285  31   1  25   4  10   1   6   3   4   3
    9   0]
 [  8   3   1   0   2   3   7  26 290   1  15   0   8   3   6   3  11   3
    7   1]
 [  5   2   0   0   0   1   6   0   4 322  34   4   1   3   2   3   5   1
    4   0]
 [  5   0   0   0   0   1   0   1   3   3 373   3   0   2   2   4   2   0
    0   0]
 [  1   9   6   3   4   2   1   0   3   2  18 301   3   1   5   3  20   4
    9   1]
 [  1  11   6  27  12   0  10  11   6   1  11  33 237  11  10   2   0   2
    2   0]
 [  4   5   0   1   0   0   3   7   4   0  15   0   5 304  11  17   9   4
    5   2]
 [  4   6   1   1   0   2   1   6   2   1  18   2   5   4 317   5   3   7
    8   1]
 [  8   3   0   1   1   2   0   1   1   1  15   1   0   2   1 343   4   0
    3  11]
 [  5   0   0   0   0   1   1   3   5   1  12  11   1   5   8  11 262   8
   16  14]
 [ 11   3   0   1   0   1   0   2   4   2   9   2   0   0   1  14  10 299
   17   0]
 [ 14   2   0   0   0   3   1   4   3   0   8   6   2   7   8   8  94  12
  136   2]
 [ 34   3   0   1   0   0   0   2   4   0   8   4   2   7   5  87  25   9
    7  53]]

________________________________________________________________________________
Training: 
BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)
train time: 0.123s
test time:  0.179s
accuracy:   0.567
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.39      0.49      0.43       319
           comp.graphics       0.54      0.64      0.59       389
 comp.os.ms-windows.misc       0.38      0.01      0.01       394
comp.sys.ibm.pc.hardware       0.48      0.70      0.57       392
   comp.sys.mac.hardware       0.29      0.79      0.42       385
          comp.windows.x       0.82      0.55      0.65       395
            misc.forsale       0.80      0.67      0.73       390
               rec.autos       0.48      0.70      0.57       396
         rec.motorcycles       0.37      0.78      0.50       398
      rec.sport.baseball       0.77      0.79      0.78       397
        rec.sport.hockey       0.97      0.70      0.82       399
               sci.crypt       0.79      0.50      0.61       396
         sci.electronics       0.58      0.57      0.58       393
                 sci.med       0.86      0.57      0.68       396
               sci.space       0.79      0.54      0.64       394
  soc.religion.christian       0.70      0.62      0.66       398
      talk.politics.guns       0.63      0.46      0.53       364
   talk.politics.mideast       0.91      0.53      0.67       376
      talk.politics.misc       0.54      0.34      0.42       310
      talk.religion.misc       0.33      0.20      0.25       251

                accuracy                           0.57      7532
               macro avg       0.62      0.56      0.56      7532
            weighted avg       0.63      0.57      0.56      7532

confusion matrix:
[[155   1   0   1  25   0   4  16  27   7   0   2   4   1   3  34   2   5
    8  24]
 [  1 248   0  24  58  13   3   4   9   0   0   8   8   3   7   1   0   1
    1   0]
 [  3  61   3 139 103  29   4   9  13   0   0   9   7   4   7   1   0   0
    0   2]
 [  0   9   2 273  74   2   7   2   3   0   0   4  16   0   0   0   0   0
    0   0]
 [  0   7   1  27 303   0   6   9   7   0   0   2  15   0   8   0   0   0
    0   0]
 [  0  70   1  18  56 216   2   3  18   1   0   3   5   2   0   0   0   0
    0   0]
 [  0   1   0  29  52   1 260  15  13   3   1   0   6   2   4   2   0   1
    0   0]
 [  1   3   0   1  34   0   6 276  57   1   0   1   9   1   1   1   1   0
    2   1]
 [  2   1   0   0  28   0   3  33 309   2   0   1  11   0   0   0   4   1
    2   1]
 [  6   2   0   2  22   0   1   7  17 314   6   0   3   1   0   1   5   0
   10   0]
 [  2   1   1   0  25   0   2  10  25  44 281   1   2   1   1   0   1   0
    2   0]
 [ 15   9   0  10  51   1   3  21  42   5   0 199  19   1   6   0   6   1
    6   1]
 [  2  15   0  27  49   1   8  19  21   3   0  14 224   7   2   0   0   0
    1   0]
 [ 11   5   0   7  40   0   5  29  35   1   0   0  19 226   6   4   1   2
    4   1]
 [ 10  15   0   2  29   2   5  34  41   3   0   0  24   5 212   2   1   1
    8   0]
 [ 56   6   0   1  23   0   2   6  24   2   0   0   2   1   0 246   2   0
    3  24]
 [ 17   0   0   1  27   0   1  32  59   3   1   3   3   2   1   2 167   3
   21  21]
 [ 48   0   0   1  16   0   2  10  34   9   0   2   4   0   1  10   6 201
   20  12]
 [ 24   1   0   1  15   0   2  25  37   7   0   1   2   3   6   3  59   3
  106  15]
 [ 49   1   0   1  19   0   0  18  38   4   0   2   3   4   3  43  10   3
    2  51]]

________________________________________________________________________________
Training: 
ComplementNB(alpha=0.1, class_prior=None, fit_prior=True, norm=False)
train time: 0.139s
test time:  0.028s
accuracy:   0.708
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.32      0.45      0.37       319
           comp.graphics       0.72      0.70      0.71       389
 comp.os.ms-windows.misc       0.73      0.52      0.61       394
comp.sys.ibm.pc.hardware       0.64      0.68      0.66       392
   comp.sys.mac.hardware       0.77      0.71      0.74       385
          comp.windows.x       0.77      0.80      0.79       395
            misc.forsale       0.74      0.72      0.73       390
               rec.autos       0.78      0.75      0.77       396
         rec.motorcycles       0.80      0.77      0.78       398
      rec.sport.baseball       0.90      0.85      0.87       397
        rec.sport.hockey       0.86      0.95      0.90       399
               sci.crypt       0.76      0.80      0.78       396
         sci.electronics       0.72      0.56      0.63       393
                 sci.med       0.76      0.80      0.78       396
               sci.space       0.77      0.80      0.78       394
  soc.religion.christian       0.58      0.88      0.70       398
      talk.politics.guns       0.60      0.68      0.64       364
   talk.politics.mideast       0.76      0.84      0.80       376
      talk.politics.misc       0.67      0.42      0.52       310
      talk.religion.misc       0.48      0.17      0.25       251

                accuracy                           0.71      7532
               macro avg       0.71      0.69      0.69      7532
            weighted avg       0.71      0.71      0.70      7532

confusion matrix:
[[143   0   3   2   2   2   2   2   1   2   8   4   3   6  12  81   9  19
    5  13]
 [ 10 274  11  13   6  31   8   1   3   3   0  12   4   0   6   1   1   3
    1   1]
 [ 22  23 206  52  11  27   9   2   4   0   2   4   4   5  10   4   1   1
    5   2]
 [  7  11  22 268  24   8  16   1   0   1   2   8  20   0   2   0   1   0
    1   0]
 [ 14   5   8  16 274  10  17   8   1   1   0   4  13   3   4   2   3   0
    0   2]
 [  7  34   8   2   4 316   1   0   0   1   3   3   2   4   4   0   4   1
    0   1]
 [  8   0   0  32  15   2 282  13   9   5   2   1   9   2   4   2   2   0
    2   0]
 [ 25   4   2   0   2   1   8 297  24   0   1   1   8   2   7   2   2   3
    4   3]
 [ 17   3   1   2   2   0   6  19 305   5   7   2   3   6   7   2   4   3
    2   2]
 [ 21   2   0   0   0   0   4   0   4 337  15   0   1   4   0   4   1   0
    4   0]
 [ 12   0   0   0   0   0   0   0   1   2 379   2   0   1   0   2   0   0
    0   0]
 [ 17   5   5   1   3   2   3   2   1   1   0 317   4   2   4   4  15   6
    2   2]
 [ 12   6   9  28  10   2  13  11   8   0   4  30 219  19  10   3   1   5
    3   0]
 [ 19   4   0   2   0   0   2   4   1   4   5   2   5 316   5  10   8   5
    3   1]
 [ 23   4   1   0   1   3   3   6   4   3   1   1   2   6 316   2   2  10
    4   2]
 [ 22   2   0   0   0   1   0   1   1   2   0   0   1   4   1 351   0   1
    5   6]
 [ 13   2   3   1   0   0   2   5   5   2   4  11   1  13   8  15 248  15
   11   5]
 [ 10   1   0   1   1   1   2   1   5   3   2   2   1   1   0  11   8 315
    8   3]
 [ 19   0   1   0   0   2   2   5   0   2   4  11   1  12   7  11  81  18
  130   4]
 [ 30   2   2   1   0   1   2   2   3   1   1   2   2  12   6 102  25  11
    3  43]]

================================================================================
LinearSVC with L1-based feature selection
________________________________________________________________________________
Training: 
Pipeline(memory=None,
         steps=[('feature_selection',
                 SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None,
                                                     dual=False,
                                                     fit_intercept=True,
                                                     intercept_scaling=1,
                                                     loss='squared_hinge',
                                                     max_iter=1000,
                                                     multi_class='ovr',
                                                     penalty='l1',
                                                     random_state=None,
                                                     tol=0.001, verbose=0),
                                 max_features=None, norm_order=1, prefit=False,
                                 threshold=None)),
                ('classification',
                 LinearSVC(C=1.0, class_weight=None, dual=True,
                           fit_intercept=True, intercept_scaling=1,
                           loss='squared_hinge', max_iter=1000,
                           multi_class='ovr', penalty='l2', random_state=None,
                           tol=0.0001, verbose=0))],
         verbose=False)
train time: 5.677s
test time:  0.024s
accuracy:   0.681
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.53      0.48      0.50       319
           comp.graphics       0.65      0.70      0.68       389
 comp.os.ms-windows.misc       0.64      0.64      0.64       394
comp.sys.ibm.pc.hardware       0.63      0.64      0.63       392
   comp.sys.mac.hardware       0.72      0.69      0.70       385
          comp.windows.x       0.82      0.70      0.75       395
            misc.forsale       0.76      0.78      0.77       390
               rec.autos       0.73      0.69      0.71       396
         rec.motorcycles       0.78      0.72      0.75       398
      rec.sport.baseball       0.52      0.82      0.64       397
        rec.sport.hockey       0.87      0.86      0.87       399
               sci.crypt       0.82      0.71      0.76       396
         sci.electronics       0.60      0.56      0.58       393
                 sci.med       0.77      0.76      0.76       396
               sci.space       0.74      0.72      0.73       394
  soc.religion.christian       0.63      0.78      0.70       398
      talk.politics.guns       0.58      0.63      0.61       364
   talk.politics.mideast       0.82      0.73      0.77       376
      talk.politics.misc       0.53      0.47      0.50       310
      talk.religion.misc       0.40      0.27      0.33       251

                accuracy                           0.68      7532
               macro avg       0.68      0.67      0.67      7532
            weighted avg       0.69      0.68      0.68      7532

confusion matrix:
[[153   2   3   2   1   0   5   4   2  11   2   1   8   8  10  52   6  11
    9  29]
 [  3 273  22   9   8  23   6   2   1  11   1   8   8   3   8   2   0   0
    0   1]
 [  3  21 251  35  14  10   2   2   2  16   3   4   1   7   9   3   2   1
    7   1]
 [  0  12  35 252  26   6  11   0   0  10   2   4  28   0   2   0   0   0
    2   2]
 [  1   8   8  25 267   4  15   3   3  16   1   3  18   3   5   2   2   0
    0   1]
 [  1  40  33   7   5 275   1   2   3   9   0   3   4   1   4   1   1   2
    1   2]
 [  1   5   2  13  17   1 304   7   3  10   1   1   9   2   2   3   4   2
    1   2]
 [  3   4   2   3   4   2  10 275  19  30   3   1  16   1   6   2   3   5
    6   1]
 [  3   2   3   2   2   0   4  24 288  25   3   1  12   4   6   4   3   1
    9   2]
 [  1   3   0   3   0   1   7   3   5 326  23   1   2   5   4   5   1   2
    5   0]
 [  1   1   2   1   1   0   0   2   3  25 344   1   0   3   1   3   5   0
    2   4]
 [  5   5   7   4   4   3   5   2   3  18   1 283  10   5   5   3  16   3
    9   5]
 [  4  10   7  31  16   7  14  14  10  15   4  13 221   8   7   2   3   2
    3   2]
 [  8   9   3   2   1   0   3   9   3  17   2   0   5 301   7  10   3   6
    5   2]
 [  4   9   5   2   4   0   4   7   7  20   2   1  16  10 284   2   5   1
   10   1]
 [ 25   2   2   3   0   1   3   0   1  14   0   2   3   5   2 311   0   2
    5  17]
 [  6   5   2   3   1   1   3   8   6  14   0  11   0   7   8   8 230  10
   26  15]
 [ 26   1   2   2   0   1   2   2   3  13   1   3   2   2   3   8   7 274
   18   6]
 [ 13   1   1   0   0   0   1   5   4  11   2   3   4   8   8   2  85   5
  146  11]
 [ 26   4   1   3   2   1   2   4   1  12   0   1   3  10   4  73  18   6
   11  69]]

Final classification report: 
1) Ridge Classifier
		Accuracy score = 0.7033988316516198		Training time = 4.832431316375732		Test time = 0.02892756462097168

2) Perceptron
		Accuracy score = 0.6343600637280935		Training time = 1.223160982131958		Test time = 0.0362241268157959

3) Passive-Aggressive
		Accuracy score = 0.6842804036112586		Training time = 1.8016140460968018		Test time = 0.029330015182495117

4) kNN
		Accuracy score = 0.06386086032926182		Training time = 0.0038819313049316406		Test time = 3.578123092651367

5) Logistic Regression [MANDATORY FOR COMP 551, ASSIGNMENT 2]
		Accuracy score = 0.6946362187997875		Training time = 46.83995604515076		Test time = 0.028139114379882812

6) Decision Tree Classifier [MANDATORY FOR COMP 551, ASSIGNMENT 2]
		Accuracy score = 0.43786510886882635		Training time = 21.53059959411621		Test time = 0.013975381851196289

7) Linear SVC (penalty = L2) [MANDATORY FOR COMP 551, ASSIGNMENT 2]
		Accuracy score = 0.6966277217206586		Training time = 6.595355987548828		Test time = 0.0691063404083252

8) Linear SVC (penalty = L1) [MANDATORY FOR COMP 551, ASSIGNMENT 2]
		Accuracy score = 0.6662241104620287		Training time = 5.292542219161987		Test time = 0.02232050895690918

9) SGD Classifier (penalty = L2)
		Accuracy score = 0.7014073287307488		Training time = 1.8264751434326172		Test time = 0.03013467788696289

10) SGD Classifier (penalty = L1)
		Accuracy score = 0.7003451938396177		Training time = 2.0614371299743652		Test time = 0.04912877082824707

11) Ada Boost Classifier [MANDATORY FOR COMP 551, ASSIGNMENT 2]
		Accuracy score = 0.36537440254912373		Training time = 8.838944673538208		Test time = 0.4961509704589844

12) Random forest [MANDATORY FOR COMP 551, ASSIGNMENT 2]
		Accuracy score = 0.626526818906001		Training time = 80.31297707557678		Test time = 1.305645227432251

13) SGDClassifier using Elastic-Net penalty
		Accuracy score = 0.6911842804036112		Training time = 3.2594752311706543		Test time = 0.02395796775817871

14) NearestCentroid (aka Rocchio classifier)
		Accuracy score = 0.6427243759957515		Training time = 0.03610539436340332		Test time = 0.02615833282470703

15) MultinomialNB(alpha=.01)
		Accuracy score = 0.6964949548592672		Training time = 0.12507295608520508		Test time = 0.029088973999023438

16) BernoulliNB(alpha=.01)
		Accuracy score = 0.5669144981412639		Training time = 0.12285137176513672		Test time = 0.17870426177978516

17) ComplementNB(alpha=.1)
		Accuracy score = 0.7084439723844929		Training time = 0.13918757438659668		Test time = 0.02807140350341797

18) LinearSVC with L1-based feature selection
		Accuracy score = 0.6806956983536909		Training time = 5.677114963531494		Test time = 0.024318695068359375



Best algorithm:
===> 17) Accuracy score = ComplementNB(alpha=.1)		Training time = 0.7084439723844929		Test time = 0.13918757438659668



DONE!
Program finished. It took 203.49358344078064 seconds

Process finished with exit code 0

