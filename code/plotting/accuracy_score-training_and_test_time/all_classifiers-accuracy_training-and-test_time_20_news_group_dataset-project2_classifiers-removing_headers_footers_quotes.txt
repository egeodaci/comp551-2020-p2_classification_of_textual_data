/home/ramon/virtual_envs/comp551_p2/bin/python /home/ramon/github/comp551-2020-p2_classification_of_textual_data/code/classification_of_text_documents.py --all_categories --report --confusion_matrix --filtered --plot_training_and_test_time_together_with_accuracy_score

##########################################################
# Classification of text documents using sparse features
##########################################################

This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.

The dataset used in this example is the 20 newsgroups dataset. It will be automatically downloaded, then cached.

https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py

Usage: classification_of_text_documents.py [options]

Options:
  -h, --help            show this help message and exit
  --report              Print a detailed classification report.
  --chi2_select=SELECT_CHI2
                        Select some number of features using a chi-squared
                        test
  --confusion_matrix    Print the confusion matrix.
  --top10               Print ten most discriminative terms per class for
                        every classifier.
  --all_categories      Whether to use all categories or not.
  --use_hashing         Use a hashing vectorizer.
  --n_features=N_FEATURES
                        n_features when using the hashing vectorizer.
  --filtered            Remove newsgroup information that is easily overfit:
                        headers, signatures, and quoting.
  --just_miniproject_classifiers
                        Use just the miniproject classifiers (1.
                        LogisticRegression, 2. DecisionTreeClassifier, 3.
                        LinearSVC (L1), 4. LinearSVC (L2), 5.
                        AdaBoostClassifier, 6. RandomForestClassifier)
  --plot_training_and_test_time_together_with_accuracy_score
                        Plot training time and test time together with
                        accuracy score

Loading 20 newsgroups dataset for categories:
all
data loaded
11314 documents - 13.782MB (training set)
7532 documents - 8.262MB (test set)
20 categories

Extracting features from the training data using a sparse vectorizer
done in 2.087521s at 6.602MB/s
n_samples: 11314, n_features: 101322

Extracting features from the test data using the same vectorizer
done in 1.136347s at 7.270MB/s
n_samples: 7532, n_features: 101322

================================================================================
Ridge Classifier
________________________________________________________________________________
Training: 
RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize=False, random_state=None, solver='sag',
                tol=0.01)
/home/ramon/virtual_envs/comp551_p2/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:558: UserWarning: "sag" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to "auto" or "sparse_cg", or set a low "tol" and a high "max_iter" (especially if inputs are not standardized).
  '"sag" solver requires many iterations to fit '
train time: 4.744s
test time:  0.029s
accuracy:   0.704
dimensionality: 101322
density: 0.999999

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.56      0.49      0.52       319
           comp.graphics       0.68      0.74      0.71       389
 comp.os.ms-windows.misc       0.65      0.65      0.65       394
comp.sys.ibm.pc.hardware       0.66      0.68      0.67       392
   comp.sys.mac.hardware       0.73      0.70      0.72       385
          comp.windows.x       0.83      0.71      0.77       395
            misc.forsale       0.75      0.79      0.77       390
               rec.autos       0.76      0.72      0.74       396
         rec.motorcycles       0.81      0.77      0.79       398
      rec.sport.baseball       0.55      0.85      0.67       397
        rec.sport.hockey       0.88      0.88      0.88       399
               sci.crypt       0.85      0.71      0.77       396
         sci.electronics       0.62      0.60      0.61       393
                 sci.med       0.79      0.79      0.79       396
               sci.space       0.75      0.76      0.75       394
  soc.religion.christian       0.65      0.82      0.72       398
      talk.politics.guns       0.60      0.68      0.64       364
   talk.politics.mideast       0.85      0.76      0.80       376
      talk.politics.misc       0.57      0.47      0.52       310
      talk.religion.misc       0.46      0.25      0.32       251

                accuracy                           0.70      7532
               macro avg       0.70      0.69      0.69      7532
            weighted avg       0.71      0.70      0.70      7532

confusion matrix:
[[156   1   4   1   1   0   8   4   0  13   3   1   7   6  11  54   7  10
    7  25]
 [  2 286  20   8   8  19   6   2   1   8   0   7  10   1   6   2   1   1
    0   1]
 [  2  19 258  32  13  12   4   3   2  17   2   3   2   6   8   1   0   1
    7   2]
 [  0  11  32 268  26   6  10   1   0   9   2   3  21   0   1   1   0   0
    1   0]
 [  2   8   8  29 271   4  12   6   1  15   1   4  14   2   2   2   3   0
    0   1]
 [  1  44  36   7   5 280   2   0   1   9   0   1   2   0   4   0   2   0
    0   1]
 [  0   2   3  13  16   0 308   8   5  11   1   1   9   3   2   2   2   1
    2   1]
 [  3   1   3   1   3   1  15 284  14  27   2   2  19   3   4   1   3   4
    5   1]
 [  5   3   0   2   2   0   7  15 306  18   3   0   8   6   7   3   3   1
    7   2]
 [  1   2   0   1   0   1   5   5   5 339  18   1   1   4   1   4   1   2
    6   0]
 [  1   1   3   0   1   0   0   2   2  25 350   0   2   4   0   0   5   0
    1   2]
 [  3   5   6   4   6   0   6   4   3  20   1 281  11   2   5   5  18   2
   12   2]
 [  4  10  11  30  12   6  15  12   6  15   4  11 234   8   8   3   1   1
    2   0]
 [  4   6   1   0   1   1   2   5   5  15   6   0   7 312   6   6   6   5
    6   2]
 [  7   9   2   2   2   1   3   8   6  20   3   1  12   8 298   1   2   0
    7   2]
 [ 19   2   4   0   0   1   1   0   2  15   0   1   3   5   4 325   0   2
    3  11]
 [  6   2   3   1   1   1   4   7   6  13   1   8   1   8   9   7 249   7
   19  11]
 [ 25   1   1   2   0   0   2   2   5  11   0   2   2   2   4   8   7 286
   14   2]
 [  9   0   0   0   2   1   1   4   4  13   2   2   6   8  10   3  85   6
  146   8]
 [ 30   5   2   3   1   2   2   2   2   9   1   1   4   8   6  75  20   6
    9  63]]

================================================================================
Perceptron
________________________________________________________________________________
Training: 
Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,
           fit_intercept=True, max_iter=50, n_iter_no_change=5, n_jobs=None,
           penalty=None, random_state=0, shuffle=True, tol=0.001,
           validation_fraction=0.1, verbose=0, warm_start=False)
train time: 0.978s
test time:  0.044s
accuracy:   0.634
dimensionality: 101322
density: 0.118555

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.49      0.45      0.46       319
           comp.graphics       0.65      0.66      0.66       389
 comp.os.ms-windows.misc       0.53      0.56      0.55       394
comp.sys.ibm.pc.hardware       0.59      0.60      0.59       392
   comp.sys.mac.hardware       0.66      0.68      0.67       385
          comp.windows.x       0.69      0.65      0.67       395
            misc.forsale       0.72      0.74      0.73       390
               rec.autos       0.70      0.66      0.68       396
         rec.motorcycles       0.75      0.66      0.70       398
      rec.sport.baseball       0.50      0.76      0.60       397
        rec.sport.hockey       0.77      0.82      0.80       399
               sci.crypt       0.77      0.67      0.72       396
         sci.electronics       0.61      0.50      0.55       393
                 sci.med       0.80      0.66      0.73       396
               sci.space       0.73      0.66      0.70       394
  soc.religion.christian       0.63      0.72      0.67       398
      talk.politics.guns       0.51      0.59      0.55       364
   talk.politics.mideast       0.77      0.72      0.75       376
      talk.politics.misc       0.43      0.41      0.42       310
      talk.religion.misc       0.33      0.31      0.32       251

                accuracy                           0.63      7532
               macro avg       0.63      0.62      0.63      7532
            weighted avg       0.64      0.63      0.63      7532

confusion matrix:
[[142   4   2   1   4   3   5   2   5  13  10   1   5   4   4  48  16   8
   10  32]
 [  3 257  22   5  14  23   6   5   0  13   3  11   8   3   6   2   0   1
    3   4]
 [  5  19 221  36  16  29   4   6   3  16   3   3   4   4   8   1   2   4
    7   3]
 [  1  14  36 236  29   9  13   3   1   7   2   5  16   2   3   2   3   0
    7   3]
 [  1   6  11  26 260   7   8   5   2  17   5   4  11   2   3   3   7   1
    5   1]
 [  3  38  36   5   9 258   7   1   1   8   3   5   4   0   6   2   3   2
    3   1]
 [  0   3   7  16  16   3 287  12   3  11   3   1   6   1   4   4   6   1
    2   4]
 [  3   1   7   9   6   1  11 260  12  29   5   2  15   0   2   2   9   8
    9   5]
 [  7   6   6   4   2   5   6  20 262  23   4   0  10   4   6   3   7   5
   12   6]
 [  8   2   3   3   0   2   4   3   9 301  18   1   4   8   4   6   5   0
   14   2]
 [  2   3   3   2   2   1   1   2   3  23 328   2   2   2   2   6   6   4
    1   4]
 [  1   6  10   9   6   3   6   5   7  20   7 266   9   2  10   3  10   3
   10   3]
 [  7  12  16  24  17   9  16  14  12  17   6   8 195   8   8   2   6   3
   12   1]
 [  7   8   7   5   1   5   3  12   6  20   7   1   5 263   2   9  10   7
   12   6]
 [  7   9   8   4   3   5   3   8   2  21   9   4  16   5 262   4  10   3
    6   5]
 [ 22   0   3   3   2   3   5   1   4  16   1   3   0   2   3 288   2   2
    4  34]
 [  9   1   7   7   1   3   2   4   7  15   3  12   4   5   5  12 215   7
   25  20]
 [ 22   1   3   3   0   2   4   2   4  11   2   3   2   2   3   9   8 272
   19   4]
 [ 13   0   1   3   4   1   4   3   5  14   3   8   2   5   9   6  74  11
  127  17]
 [ 29   3   6   2   4   3   2   2   2  10   3   5   4   6   8  46  21  10
    7  78]]

================================================================================
Passive-Aggressive
________________________________________________________________________________
Training: 
PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,
                            early_stopping=False, fit_intercept=True,
                            loss='hinge', max_iter=50, n_iter_no_change=5,
                            n_jobs=None, random_state=None, shuffle=True,
                            tol=0.001, validation_fraction=0.1, verbose=0,
                            warm_start=False)
train time: 1.758s
test time:  0.034s
accuracy:   0.682
dimensionality: 101322
density: 0.415445

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.51      0.49      0.50       319
           comp.graphics       0.64      0.71      0.67       389
 comp.os.ms-windows.misc       0.62      0.58      0.60       394
comp.sys.ibm.pc.hardware       0.62      0.63      0.63       392
   comp.sys.mac.hardware       0.71      0.69      0.70       385
          comp.windows.x       0.80      0.71      0.75       395
            misc.forsale       0.75      0.77      0.76       390
               rec.autos       0.76      0.72      0.74       396
         rec.motorcycles       0.49      0.77      0.60       398
      rec.sport.baseball       0.86      0.80      0.83       397
        rec.sport.hockey       0.87      0.86      0.87       399
               sci.crypt       0.81      0.71      0.76       396
         sci.electronics       0.64      0.57      0.60       393
                 sci.med       0.78      0.75      0.77       396
               sci.space       0.74      0.73      0.73       394
  soc.religion.christian       0.65      0.75      0.70       398
      talk.politics.guns       0.59      0.64      0.61       364
   talk.politics.mideast       0.85      0.75      0.80       376
      talk.politics.misc       0.53      0.44      0.48       310
      talk.religion.misc       0.41      0.33      0.37       251

                accuracy                           0.68      7532
               macro avg       0.68      0.67      0.67      7532
            weighted avg       0.69      0.68      0.68      7532

confusion matrix:
[[155   1   2   2   2   1   1   2  17   3   3   7   5   6   8  45  10  10
    9  30]
 [  2 275  19   6   8  22   5   3   9   1   2   9   7   3  10   2   1   1
    1   3]
 [  4  24 229  44  14  15   5   2  18   1   2   2   2   5  10   2   2   2
    8   3]
 [  0  17  36 246  26   6  12   2   7   2   2   5  24   1   2   0   0   1
    2   1]
 [  3  10   9  26 266   4  15   5  17   1   2   3  14   2   1   3   4   0
    0   0]
 [  1  43  33   6   3 279   5   1   8   1   0   2   4   1   4   1   1   1
    0   1]
 [  1   3   4  13  18   2 300  10  12   1   1   1  10   2   1   2   3   3
    2   1]
 [  4   2   1   2   4   3  13 287  40   2   3   1  16   2   6   1   3   3
    3   0]
 [  6   4   1   1   4   1   7  15 308   5   1   0   7   3   7   4   6   1
   12   5]
 [  2   2   0   2   0   1   4   4  23 318  18   0   2   4   3   5   2   1
    6   0]
 [  1   0   1   1   2   0   0   1  16  14 345   0   1   2   1   3   5   0
    1   5]
 [  4   6   5   7   3   4   4   3  21   2   2 283   8   3   6   3  13   1
   13   5]
 [  4  11  14  24  16   5  16   9  20   4   4  13 224  10  10   3   1   1
    4   0]
 [  4   7   1   2   1   0   1   9  24   1   4   0   9 298   9   8   6   3
    5   4]
 [  9  11   5   3   1   1   3   8  24   1   3   2  11   5 289   2   5   2
    6   3]
 [ 23   1   2   3   1   1   3   0  16   0   0   1   1   5   4 300   0   1
    5  31]
 [  8   4   4   1   1   1   4   7  19   1   0   9   0   9   7   9 234   9
   24  13]
 [ 28   1   1   2   0   0   2   4  13   3   2   1   1   3   0  11   6 282
   13   3]
 [ 14   1   0   1   0   2   0   4  12   5   2   3   3   9  10   1  83   8
  137  15]
 [ 31   5   2   3   3   1   1   3  10   2   1   7   3   7   5  58  14   3
    8  84]]

================================================================================
kNN
________________________________________________________________________________
Training: 
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,
                     weights='uniform')
train time: 0.004s
test time:  3.432s
accuracy:   0.064
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.05      0.08      0.06       319
           comp.graphics       0.04      0.09      0.06       389
 comp.os.ms-windows.misc       0.06      0.18      0.09       394
comp.sys.ibm.pc.hardware       0.09      0.05      0.07       392
   comp.sys.mac.hardware       0.05      0.09      0.06       385
          comp.windows.x       0.29      0.01      0.02       395
            misc.forsale       0.19      0.06      0.09       390
               rec.autos       0.06      0.17      0.09       396
         rec.motorcycles       0.09      0.07      0.08       398
      rec.sport.baseball       0.07      0.12      0.08       397
        rec.sport.hockey       0.10      0.06      0.07       399
               sci.crypt       0.06      0.04      0.05       396
         sci.electronics       0.06      0.04      0.05       393
                 sci.med       0.05      0.03      0.04       396
               sci.space       0.11      0.05      0.06       394
  soc.religion.christian       0.11      0.02      0.03       398
      talk.politics.guns       0.03      0.01      0.02       364
   talk.politics.mideast       0.11      0.07      0.08       376
      talk.politics.misc       0.02      0.01      0.01       310
      talk.religion.misc       0.03      0.02      0.02       251

                accuracy                           0.06      7532
               macro avg       0.08      0.06      0.06      7532
            weighted avg       0.09      0.06      0.06      7532

confusion matrix:
[[26 34 42 13 29  0  5 51  5 33 11 11  9 12  6  2  3  9 12  6]
 [29 36 71 16 27  0  5 48 19 41 11 13  9  8 10  3  9 21  4  9]
 [26 41 72 12 40  1  5 58 14 32 15  8 13 14 14  1  5  9  8  6]
 [29 33 62 21 46  1  5 51 13 30 13 15 10 10  8  5 10 13  9  8]
 [36 43 45 10 35  0  2 69 16 29 14  7 16 14  3  3  8 16 11  8]
 [29 47 68  5 35  4  3 61 25 29  9 14 10 13  6  4  7 12  5  9]
 [25 40 57 19 38  2 22 52 15 30 15 13 14  9  8  1  3 11  5 11]
 [24 53 62 14 52  1  4 68 11 27 19  9  9  6  7  2  3  8  9  8]
 [32 38 49 15 32  2  8 58 27 37  7 13 15 11  8  1 10 16 10  9]
 [35 43 73 18 33  0  4 66 13 46  6  7  8 10  7  3  5  6  5  9]
 [29 47 61 12 39  0  2 55 13 37 23 12  7 12  8  3 10 11 12  6]
 [29 49 52  6 37  0  6 68 16 38 13 14 14 13  6  3  7 11  5  9]
 [21 36 58 15 33  0  7 67 14 38 14 12 14 20  6  2  6 10  9 11]
 [29 46 59 10 41  1  6 55 15 45 10 13 13 12  7  3 11 10  5  5]
 [30 40 61 11 27  0  9 68 13 31 10  9 12 14 18  1 11 10  7 12]
 [31 44 55 16 40  1  7 60 12 37  8 15 11 11  9  6  8  8 12  7]
 [27 42 64  6 33  0  4 57 16 44  9 12  8 11  8  1  4 11  4  3]
 [25 35 57 10 33  0  3 63 11 37  7  7  9  7 10  9  5 26  9 13]
 [14 32 51 14 35  1  2 43  9 28  8 10 15  7 10  3 11 10  3  4]
 [17 28 42  4 25  0  4 40 12 18  9  6  9  7  2  1  3 16  4  4]]

================================================================================
Logistic Regression
________________________________________________________________________________
Training: 
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
train time: 46.770s
test time:  0.028s
accuracy:   0.695
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.48      0.46      0.47       319
           comp.graphics       0.64      0.71      0.67       389
 comp.os.ms-windows.misc       0.66      0.63      0.64       394
comp.sys.ibm.pc.hardware       0.68      0.65      0.66       392
   comp.sys.mac.hardware       0.76      0.69      0.72       385
          comp.windows.x       0.84      0.72      0.78       395
            misc.forsale       0.77      0.78      0.78       390
               rec.autos       0.75      0.73      0.74       396
         rec.motorcycles       0.48      0.81      0.61       398
      rec.sport.baseball       0.81      0.83      0.82       397
        rec.sport.hockey       0.92      0.87      0.89       399
               sci.crypt       0.89      0.68      0.77       396
         sci.electronics       0.57      0.62      0.59       393
                 sci.med       0.78      0.79      0.79       396
               sci.space       0.71      0.75      0.73       394
  soc.religion.christian       0.65      0.82      0.72       398
      talk.politics.guns       0.58      0.68      0.63       364
   talk.politics.mideast       0.85      0.76      0.80       376
      talk.politics.misc       0.61      0.44      0.51       310
      talk.religion.misc       0.57      0.18      0.27       251

                accuracy                           0.69      7532
               macro avg       0.70      0.68      0.68      7532
            weighted avg       0.71      0.69      0.69      7532

confusion matrix:
[[146   2   3   1   1   2   1   5  19   6   1   1   3  10  17  66   6  12
    6  11]
 [  5 278  22   7   6  19   7   2  10   4   0   4  14   1   9   1   0   0
    0   0]
 [  4  21 247  39  14  13   2   3  19   2   1   3   2   8  10   0   2   0
    3   1]
 [  1  14  35 255  26   3  11   2   8   1   1   1  33   0   1   0   0   0
    0   0]
 [  2   7  10  27 266   3  13   2  16   2   1   1  26   4   4   1   0   0
    0   0]
 [  0  45  28   8   3 286   1   2   9   1   0   2   3   2   4   0   0   0
    1   0]
 [  0   2   2  15  15   0 306  10  13   2   1   1  13   2   3   1   3   0
    1   0]
 [  1   0   1   0   2   1  11 288  43   6   0   0  21   1   9   1   4   2
    4   1]
 [  5   2   0   0   1   0   7  19 323   6   0   0  12   4   7   2   3   0
    7   0]
 [  2   4   0   1   0   2   3   3  23 329  16   0   2   3   0   3   0   3
    3   0]
 [  4   2   0   0   1   0   0   3  14  17 346   0   1   2   0   0   6   1
    2   0]
 [  3  11   5   3   5   3   4   2  24   4   1 271  13   6   7   1  20   4
    9   0]
 [  4  19  12  19  10   2  14  12  19   5   0  12 242   8   9   2   1   2
    1   0]
 [  7   7   1   1   0   2   6   6  23   0   2   0   8 314   4   5   3   1
    5   1]
 [  6  11   2   0   1   1   4   7  23   3   2   0  13  11 295   2   5   2
    6   0]
 [ 19   3   3   0   0   0   1   0  20   3   0   0   2   3   5 326   2   3
    2   6]
 [ 10   1   2   0   1   1   2   7  22   3   1   7   3   5   9   8 249   6
   19   8]
 [ 24   2   2   0   0   0   1   3  15   6   0   2   4   2   2   7   8 284
   13   1]
 [ 16   1   0   0   0   1   2   2  13   3   2   1   4   7  12   2  94   9
  137   4]
 [ 43   3   2   0   0   1   1   4  12   3   2   0   3  10   8  76  25   7
    7  44]]

================================================================================
Decision Tree Classifier
________________________________________________________________________________
Training: 
DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=None, splitter='best')
train time: 19.250s
test time:  0.014s
accuracy:   0.439
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.29      0.26      0.27       319
           comp.graphics       0.42      0.44      0.43       389
 comp.os.ms-windows.misc       0.42      0.44      0.43       394
comp.sys.ibm.pc.hardware       0.40      0.37      0.38       392
   comp.sys.mac.hardware       0.43      0.45      0.44       385
          comp.windows.x       0.53      0.45      0.49       395
            misc.forsale       0.61      0.55      0.58       390
               rec.autos       0.26      0.53      0.35       396
         rec.motorcycles       0.56      0.54      0.55       398
      rec.sport.baseball       0.52      0.49      0.50       397
        rec.sport.hockey       0.59      0.63      0.61       399
               sci.crypt       0.56      0.46      0.51       396
         sci.electronics       0.28      0.26      0.27       393
                 sci.med       0.49      0.42      0.46       396
               sci.space       0.51      0.48      0.50       394
  soc.religion.christian       0.52      0.50      0.51       398
      talk.politics.guns       0.37      0.43      0.40       364
   talk.politics.mideast       0.61      0.54      0.57       376
      talk.politics.misc       0.25      0.18      0.21       310
      talk.religion.misc       0.20      0.17      0.18       251

                accuracy                           0.44      7532
               macro avg       0.44      0.43      0.43      7532
            weighted avg       0.45      0.44      0.44      7532

confusion matrix:
[[ 82   9   3   2   6   2   3  31  10   8   8   5   7   8  14  44  14  18
   10  35]
 [  1 172  32  26  23  36   4  20   4   5   4   6  23  11   8   1   6   3
    2   2]
 [  1  27 172  44  30  29   5  25   8   7   2   2   7   8   7   1   4   8
    4   3]
 [  6  27  37 144  40  17  17  27   9   5   2   3  31   9   5   3   4   3
    2   1]
 [  2  21   9  28 175   8  17  35   7   5   1  15  22   7  14   0   5   6
    5   3]
 [  3  39  52  24  16 179   6  23   2   3   2   8  10   6   5   0   5   5
    4   3]
 [  0  10  11  18  21   5 216  34   7   7  14   7  15   1   9   4   3   1
    5   2]
 [  3   7   8   5  14   7  15 208  23   9   7   4  23  11  13   3  13   9
    9   5]
 [  7   6   7   8   8   3  13  43 214  13   6   9  12   5   7   5  14   4
    9   5]
 [  6   2   6   2   4   3   4  37   7 196  75   2   5   4  14   2  10   7
    5   6]
 [  2   3   3   1   0   3   3  27  11  60 250   1   2   6   6   1   7   3
    5   5]
 [  6  21  10   9  10   4   3  42   6   5   2 183  18   4   7   4  33  11
   12   6]
 [  6  23  19  26  35   6  23  44  14  10  11  18 104  16  14   1   8   5
    7   3]
 [ 12  13  13   7   8   7   8  38  15   8   6   4  31 168  15   4  12   8
   13   6]
 [  9  10   6   8   6   3   5  45   5   6  12  11  20  18 190   8  13   3
   12   4]
 [ 39   2   5   0   2   6   3  23   3  10   3   4   9   9   5 200   8  11
   13  43]
 [ 17   7   9   4   6   6   5  29  12   5   4  15   4  11  17  16 155   8
   18  16]
 [ 26   6   0   1   3   5   1  19   8   9   3   9   5   7   4  15  17 202
   26  10]
 [ 23   3   3   4   2   4   1  28  12   6   7  13  14  22  13  15  66   9
   57   8]
 [ 32   6   4   0   2   2   5  24   7   3   8   6   3  10   4  59  18   9
    7  42]]

================================================================================
Linear SVC (penalty = L2)
________________________________________________________________________________
Training: 
LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.001,
          verbose=0)
train time: 9.903s
test time:  0.069s
accuracy:   0.697
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.54      0.49      0.51       319
           comp.graphics       0.66      0.72      0.69       389
 comp.os.ms-windows.misc       0.62      0.62      0.62       394
comp.sys.ibm.pc.hardware       0.65      0.66      0.66       392
   comp.sys.mac.hardware       0.73      0.70      0.72       385
          comp.windows.x       0.83      0.70      0.76       395
            misc.forsale       0.75      0.79      0.77       390
               rec.autos       0.75      0.71      0.73       396
         rec.motorcycles       0.79      0.76      0.77       398
      rec.sport.baseball       0.55      0.86      0.67       397
        rec.sport.hockey       0.87      0.87      0.87       399
               sci.crypt       0.83      0.72      0.77       396
         sci.electronics       0.63      0.59      0.61       393
                 sci.med       0.79      0.78      0.79       396
               sci.space       0.75      0.75      0.75       394
  soc.religion.christian       0.65      0.79      0.71       398
      talk.politics.guns       0.60      0.66      0.63       364
   talk.politics.mideast       0.84      0.76      0.80       376
      talk.politics.misc       0.55      0.46      0.50       310
      talk.religion.misc       0.45      0.29      0.35       251

                accuracy                           0.70      7532
               macro avg       0.69      0.68      0.68      7532
            weighted avg       0.70      0.70      0.69      7532

confusion matrix:
[[155   2   4   1   1   0   4   3   4  11   4   3   7   5   8  54   7  13
    9  24]
 [  4 279  20   9   6  21   6   2   0   9   0  11   8   2   8   2   1   0
    0   1]
 [  3  22 243  37  16  11   3   4   1  16   2   3   3   6   9   2   1   2
    8   2]
 [  0  10  38 260  26   6  12   1   0   9   2   4  21   0   1   0   0   0
    2   0]
 [  2  10   8  25 271   6  14   5   1  16   1   2  16   2   1   1   3   0
    0   1]
 [  1  41  39   5   4 278   2   1   1   9   0   2   3   1   5   0   2   0
    0   1]
 [  0   3   2  12  15   0 308   8   6  10   2   1   9   2   2   2   2   3
    2   1]
 [  2   1   3   3   3   1  13 283  17  26   3   2  16   3   5   2   4   4
    5   0]
 [  5   3   1   1   2   0   7  18 302  19   2   0   9   4   7   3   4   1
    8   2]
 [  1   2   0   2   0   1   6   3   5 340  17   0   2   4   1   4   1   2
    6   0]
 [  0   1   2   2   1   0   1   2   2  27 347   0   1   3   0   1   5   0
    1   3]
 [  5   6   5   4   4   1   6   2   4  19   1 285  10   3   5   4  12   2
   15   3]
 [  4  12   9  28  13   6  13  11   9  15   4  10 233   8   9   3   1   1
    3   1]
 [  5   6   4   1   1   0   1   9   4  15   5   0   7 309   6   5   5   5
    5   3]
 [  6  11   5   2   3   1   3  11   6  20   3   0   8   6 296   1   4   0
    6   2]
 [ 21   1   3   0   0   1   2   0   1  15   0   3   3   5   3 315   0   1
    5  19]
 [  8   3   3   1   1   0   4   7   7  13   0  10   1   9   7   9 242   8
   20  11]
 [ 25   1   1   2   0   0   2   2   7   9   1   1   2   3   3   8   8 284
   14   3]
 [  9   1   0   1   2   1   0   4   5  11   2   3   4   8  11   1  84   7
  144  12]
 [ 31   6   2   3   2   1   1   2   1  10   1   2   4   7   6  67  19   5
    8  73]]

================================================================================
Linear SVC (penalty = L1)
________________________________________________________________________________
Training: 
LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,
          verbose=0)
train time: 4.020s
test time:  0.021s
accuracy:   0.666
dimensionality: 101322
density: 0.005262

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.46      0.45      0.45       319
           comp.graphics       0.66      0.72      0.69       389
 comp.os.ms-windows.misc       0.64      0.63      0.63       394
comp.sys.ibm.pc.hardware       0.60      0.66      0.63       392
   comp.sys.mac.hardware       0.70      0.67      0.68       385
          comp.windows.x       0.82      0.66      0.73       395
            misc.forsale       0.72      0.75      0.74       390
               rec.autos       0.46      0.74      0.57       396
         rec.motorcycles       0.78      0.71      0.74       398
      rec.sport.baseball       0.83      0.74      0.78       397
        rec.sport.hockey       0.83      0.84      0.84       399
               sci.crypt       0.81      0.71      0.75       396
         sci.electronics       0.56      0.54      0.55       393
                 sci.med       0.79      0.72      0.76       396
               sci.space       0.75      0.71      0.73       394
  soc.religion.christian       0.62      0.76      0.68       398
      talk.politics.guns       0.57      0.66      0.61       364
   talk.politics.mideast       0.86      0.70      0.78       376
      talk.politics.misc       0.52      0.45      0.48       310
      talk.religion.misc       0.38      0.28      0.32       251

                accuracy                           0.67      7532
               macro avg       0.67      0.65      0.66      7532
            weighted avg       0.68      0.67      0.67      7532

confusion matrix:
[[142   2   3   2   1   0   6  16   7   2   4   3   6   7  11  61   8   7
    5  26]
 [  3 279  19  11   8  20   5   9   2   2   1   9   6   1   9   1   0   1
    1   2]
 [  6  19 247  40  11  12   2  18   1   1   2   4   3   5   6   4   4   0
    8   1]
 [  0  11  35 258  24   3   9   9   0   2   2   5  29   0   1   2   1   0
    0   1]
 [  2  12   7  27 258   4  10  16   5   2   3   2  22   5   4   3   2   0
    0   1]
 [  1  45  39   5   5 262   5   9   1   1   1   3   6   0   6   1   2   2
    0   1]
 [  0   1   3  22  16   0 294  19   1   3   2   1  11   2   5   1   5   1
    1   2]
 [  4   2   2   6   2   2  15 294  15   2   2   2  19   4   4   4   3   4
    9   1]
 [  5   2   2   2   2   1   6  43 283   6   1   2  13   4   5   4   3   0
    9   5]
 [  3   3   0   4   1   1   9  29   5 293  26   0   3   3   1   5   1   1
    5   4]
 [  1   2   3   2   5   1   0  12   4  18 334   1   2   1   1   3   3   0
    4   2]
 [  4   5   7   4   6   2  11  20   4   0   2 280  11   2   4   2  18   2
    9   3]
 [  5  11   5  34  18   4  15  27   6   6   6   9 213   8   7   5   7   1
    4   2]
 [  9  10   2   2   1   0   6  26   7   1   6   2   6 287   6   7   6   1
    8   3]
 [  6  11   3   4   4   2   3  24   6   3   1   2  16  10 279   4   2   0
   11   3]
 [ 25   2   1   0   2   1   1  15   3   1   0   4   3   4   2 301   3   6
    5  19]
 [  8   4   4   2   2   1   1  19   6   4   0   9   2   3   9   6 239   6
   23  16]
 [ 28   0   2   2   1   1   3   8   2   4   1   4   2   3   2  16  12 265
   16   4]
 [ 10   1   0   0   1   2   2  12   4   1   5   4   7   9   6   3  78   6
  140  19]
 [ 44   3   1   1   1   2   6  15   2   2   1   1   3   4   5  56  20   4
   10  70]]

================================================================================
SGD Classifier (penalty = L2)
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,
              random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 1.509s
test time:  0.033s
accuracy:   0.701
dimensionality: 101322
density: 0.321607

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.53      0.48      0.51       319
           comp.graphics       0.68      0.73      0.71       389
 comp.os.ms-windows.misc       0.63      0.63      0.63       394
comp.sys.ibm.pc.hardware       0.67      0.65      0.66       392
   comp.sys.mac.hardware       0.73      0.71      0.72       385
          comp.windows.x       0.81      0.72      0.76       395
            misc.forsale       0.77      0.80      0.78       390
               rec.autos       0.78      0.72      0.75       396
         rec.motorcycles       0.82      0.76      0.79       398
      rec.sport.baseball       0.54      0.86      0.66       397
        rec.sport.hockey       0.86      0.89      0.87       399
               sci.crypt       0.83      0.71      0.77       396
         sci.electronics       0.64      0.57      0.60       393
                 sci.med       0.78      0.80      0.79       396
               sci.space       0.74      0.76      0.75       394
  soc.religion.christian       0.64      0.82      0.72       398
      talk.politics.guns       0.59      0.68      0.63       364
   talk.politics.mideast       0.85      0.76      0.80       376
      talk.politics.misc       0.60      0.46      0.52       310
      talk.religion.misc       0.48      0.25      0.33       251

                accuracy                           0.70      7532
               macro avg       0.70      0.69      0.69      7532
            weighted avg       0.71      0.70      0.70      7532

confusion matrix:
[[154   2   2   1   1   2   4   3   2  13   7   3   6   5  11  59   6  12
    5  21]
 [  2 285  20  10   7  20   5   3   1   9   0   7   6   3   7   1   1   1
    0   1]
 [  6  22 249  31  13  14   5   3   0  16   2   3   1   6   9   2   3   1
    7   1]
 [  0  12  37 255  31   5  12   0   1   8   2   4  22   0   1   0   0   0
    2   0]
 [  3   5   8  27 273   5  12   3   2  15   1   6  12   2   2   3   4   0
    1   1]
 [  0  40  35   6   6 284   1   0   1   9   0   2   4   0   4   0   2   0
    0   1]
 [  0   3   2  11  15   0 311   6   3  11   3   1  10   3   4   1   2   1
    2   1]
 [  1   1   1   1   4   0  13 286  17  28   2   1  19   2   5   1   4   4
    4   2]
 [  3   3   1   1   1   0   5  18 302  19   3   0  10   6   9   4   4   0
    7   2]
 [  1   2   0   0   0   1   5   4   5 341  19   0   1   3   1   5   1   2
    6   0]
 [  0   0   2   1   1   0   0   1   2  24 354   0   1   3   1   1   6   0
    1   1]
 [  3   6   6   4   3   4   6   3   4  19   1 282   9   2   4   7  14   4
   12   3]
 [  4  11  13  27  16   7  14   9   8  16   4  11 225  10  10   2   2   1
    2   1]
 [  6   6   4   0   0   0   2   6   3  16   5   0   7 315   5   6   5   2
    6   2]
 [  7  11   3   0   1   0   3   8   2  19   3   1  10   9 301   4   3   1
    6   2]
 [ 22   2   3   0   0   1   2   0   1  17   1   1   2   5   3 326   0   2
    4   6]
 [  7   3   3   2   2   2   3   4   6  16   1   9   0   9   8   8 246   7
   14  14]
 [ 28   0   2   2   0   2   2   3   4  10   1   3   2   3   3   7   7 287
   10   0]
 [  9   0   0   0   2   2   0   4   3  15   3   3   4   9  13   3  84   5
  144   7]
 [ 32   4   3   4   0   2   1   3   1   9   2   1   3  11   7  71  20   8
    7  62]]

================================================================================
SGD Classifier (penalty = L1)
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,
              random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 1.485s
test time:  0.031s
accuracy:   0.700
dimensionality: 101322
density: 0.313595

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.54      0.47      0.50       319
           comp.graphics       0.68      0.74      0.70       389
 comp.os.ms-windows.misc       0.64      0.64      0.64       394
comp.sys.ibm.pc.hardware       0.67      0.65      0.66       392
   comp.sys.mac.hardware       0.73      0.70      0.72       385
          comp.windows.x       0.82      0.71      0.76       395
            misc.forsale       0.76      0.80      0.78       390
               rec.autos       0.76      0.72      0.74       396
         rec.motorcycles       0.82      0.75      0.79       398
      rec.sport.baseball       0.84      0.81      0.82       397
        rec.sport.hockey       0.87      0.89      0.88       399
               sci.crypt       0.83      0.72      0.77       396
         sci.electronics       0.63      0.58      0.60       393
                 sci.med       0.78      0.80      0.79       396
               sci.space       0.73      0.77      0.75       394
  soc.religion.christian       0.64      0.81      0.72       398
      talk.politics.guns       0.59      0.67      0.63       364
   talk.politics.mideast       0.51      0.79      0.62       376
      talk.politics.misc       0.59      0.46      0.52       310
      talk.religion.misc       0.47      0.25      0.33       251

                accuracy                           0.70      7532
               macro avg       0.70      0.69      0.69      7532
            weighted avg       0.70      0.70      0.70      7532

confusion matrix:
[[150   3   2   1   1   2   4   3   1   5   6   3   6   6  11  56   7  21
    6  25]
 [  2 286  20  10   7  18   5   3   1   3   0   9   6   1   8   1   1   7
    0   1]
 [  3  21 252  31  13  13   6   3   1   1   1   3   1   6   9   2   3  17
    7   1]
 [  0  12  36 255  29   6  13   0   1   1   2   4  23   0   1   0   0   7
    2   0]
 [  3   5   9  26 271   4  13   4   1   1   1   6  13   2   2   4   4  14
    1   1]
 [  0  44  34   6   6 282   1   0   0   2   0   2   4   0   4   0   2   7
    0   1]
 [  0   3   2  10  15   0 311   7   3   3   2   1  10   3   4   2   2   9
    2   1]
 [  1   0   3   0   4   0  13 286  16   4   2   1  18   2   7   1   4  28
    4   2]
 [  1   3   1   1   1   0   6  20 300   6   2   0  11   5   9   4   5  13
    8   2]
 [  1   2   0   0   0   1   5   4   5 321  20   0   1   4   2   5   1  19
    6   0]
 [  0   0   2   1   1   0   0   1   2  13 355   0   1   3   1   1   6  10
    1   1]
 [  3   5   6   4   3   4   6   4   4   2   0 285   9   2   4   6  14  21
   11   3]
 [  4  13  11  28  15   7  14   9   9   4   3  12 226  10   9   2   2  12
    2   1]
 [  7   5   4   0   0   0   2   7   2   1   4   0   6 315   6   6   6  18
    6   1]
 [  6  11   2   0   1   0   3   8   2   1   2   1  10  10 302   2   3  20
    8   2]
 [ 22   2   3   0   0   1   2   0   2   1   1   1   2   5   3 324   0  16
    5   8]
 [  7   3   3   2   2   2   3   5   6   5   1  10   1   7   8   7 245  20
   15  12]
 [ 24   1   1   1   0   2   2   3   5   3   1   3   2   2   2   7   7 298
   11   1]
 [ 10   0   0   1   1   2   0   4   2   5   3   3   4  10  14   3  84  13
  144   7]
 [ 32   4   3   4   0   2   1   3   1   2   2   1   2  11   7  70  21  15
    7  63]]

================================================================================
Ada Boost Classifier
________________________________________________________________________________
Training: 
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=None)
train time: 9.574s
test time:  0.643s
accuracy:   0.365
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.00      0.00      0.00       319
           comp.graphics       0.60      0.23      0.33       389
 comp.os.ms-windows.misc       0.64      0.40      0.49       394
comp.sys.ibm.pc.hardware       0.48      0.31      0.38       392
   comp.sys.mac.hardware       0.69      0.37      0.48       385
          comp.windows.x       0.73      0.41      0.52       395
            misc.forsale       0.75      0.52      0.61       390
               rec.autos       0.79      0.38      0.52       396
         rec.motorcycles       0.92      0.33      0.48       398
      rec.sport.baseball       0.74      0.19      0.30       397
        rec.sport.hockey       0.64      0.57      0.60       399
               sci.crypt       0.80      0.42      0.55       396
         sci.electronics       0.08      0.82      0.15       393
                 sci.med       0.88      0.21      0.34       396
               sci.space       0.73      0.34      0.46       394
  soc.religion.christian       0.52      0.65      0.58       398
      talk.politics.guns       0.48      0.24      0.32       364
   talk.politics.mideast       0.96      0.50      0.65       376
      talk.politics.misc       0.29      0.17      0.21       310
      talk.religion.misc       0.14      0.01      0.02       251

                accuracy                           0.37      7532
               macro avg       0.59      0.35      0.40      7532
            weighted avg       0.61      0.37      0.41      7532

confusion matrix:
[[  0   0   0   0   0   3   2   0   0   0   3   4 190   1   5  95   6   1
    6   3]
 [  0  90  16  12   7  23   4   1   0   0   3   2 224   0   7   0   0   0
    0   0]
 [  0  21 157  23  15  20   2   1   0   0   1   0 148   1   3   0   2   0
    0   0]
 [  0  12  27 121   8   3   5   0   0   0   1   2 207   2   4   0   0   0
    0   0]
 [  1   2   1  27 142   0  12   0   0   0   2   5 188   0   4   0   0   0
    1   0]
 [  0   9  32   4   3 162   2   0   0   0   0   4 170   0   4   0   0   1
    3   1]
 [  0   6   5  23   9   1 202  10   2   1   3   2 120   0   3   2   1   0
    0   0]
 [  0   0   2  10   0   0   8 152   4   0   1   1 206   0   1   1   9   0
    1   0]
 [  0   0   0  12   0   1   4   7 131   1   1   2 228   1   1   4   4   0
    1   0]
 [  0   1   0   3   0   0   3   0   0  75  92   1 215   0   1   1   2   0
    1   2]
 [  0   0   0   0   0   1   7   0   1  18 228   0 140   0   0   1   1   0
    1   1]
 [  0   0   0   2   6   1   1   0   1   0   0 168 167   0   3   1  16   2
   28   0]
 [  1   6   2  12   6   2   7  13   1   1   2  13 322   0   4   0   0   0
    1   0]
 [  3   0   0   0   1   0   2   0   0   0   0   0 293  84   0  10   1   0
    2   0]
 [  3   1   1   1   9   3   3   3   1   0   8   2 212   4 132   2   2   0
    7   0]
 [  4   1   0   0   0   0   1   0   0   0   0   0 122   0   1 257   0   2
    4   6]
 [  0   0   2   1   0   3   3   1   2   1   6   3 194   0   4  12  87   1
   43   1]
 [  1   0   0   0   0   0   0   0   0   1   0   1 138   0   1  15   9 187
   20   3]
 [  0   0   0   0   1   0   0   2   0   2   4   0 202   3   1   8  34   0
   52   1]
 [  1   0   1   1   0   0   1   3   0   1   1   1 136   0   1  84   9   1
    7   3]]

================================================================================
Random forest
________________________________________________________________________________
Training: 
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False)
train time: 70.340s
test time:  1.028s
accuracy:   0.624
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.45      0.40      0.42       319
           comp.graphics       0.57      0.62      0.59       389
 comp.os.ms-windows.misc       0.54      0.64      0.58       394
comp.sys.ibm.pc.hardware       0.62      0.57      0.60       392
   comp.sys.mac.hardware       0.63      0.64      0.64       385
          comp.windows.x       0.67      0.69      0.68       395
            misc.forsale       0.70      0.72      0.71       390
               rec.autos       0.42      0.68      0.51       396
         rec.motorcycles       0.67      0.68      0.67       398
      rec.sport.baseball       0.69      0.79      0.73       397
        rec.sport.hockey       0.83      0.82      0.82       399
               sci.crypt       0.80      0.65      0.72       396
         sci.electronics       0.54      0.44      0.49       393
                 sci.med       0.74      0.67      0.70       396
               sci.space       0.70      0.66      0.68       394
  soc.religion.christian       0.59      0.78      0.68       398
      talk.politics.guns       0.54      0.60      0.57       364
   talk.politics.mideast       0.82      0.69      0.75       376
      talk.politics.misc       0.54      0.33      0.41       310
      talk.religion.misc       0.33      0.11      0.16       251

                accuracy                           0.62      7532
               macro avg       0.62      0.61      0.61      7532
            weighted avg       0.63      0.62      0.62      7532

confusion matrix:
[[127   0   3   2   2   3   8  19   8   8   6   4   0  10  13  75   8   5
    7  11]
 [  2 241  40  10  12  33   4  11   7   2   2   3   6   3  12   1   0   0
    0   0]
 [  2  24 251  27  15  23   2  16   5   6   1   3   2   0   7   1   3   4
    1   1]
 [  2  17  51 225  33   7  12  10   1   3   2   3  25   1   0   0   0   0
    0   0]
 [  0  10  14  29 247   9  18  21   4   5   2   3  16   2   3   0   0   0
    2   0]
 [  1  35  39   9   5 273   6  10   1   2   1   2   2   1   3   1   1   0
    2   1]
 [  0   9   5  21  21   1 282  17   6   4   1   1   7   1   7   1   4   0
    1   1]
 [  6   6   6   3   7  10  16 268  27   3   3   1  15   5   5   3   7   1
    4   0]
 [  4   1   3   1   1   3  10  46 271  15   2   1  10   3   4   4   4   6
    7   2]
 [  1   6   3   2   0   2   1  24   8 312  25   0   0   2   3   2   1   1
    4   0]
 [  2   2   1   1   3   1   1  14   2  33 326   0   0   2   2   1   2   2
    3   1]
 [  5  11   6   5   9   7   5  22   4   2   1 259  13   2   7   2  22   3
    9   2]
 [  3  22  19  25  24  15  14  30   9  12   6  12 174  13   9   0   2   2
    1   1]
 [  7  13   6   0   3   5  11  26   9   8   2   1  12 266   6   6   4   3
    6   2]
 [  4  11   6   1   5   3   4  30   9  11   3   2  17   8 259   6   6   4
    3   2]
 [ 17   4   5   1   0   2   1  16   6   3   1   0   2   2   5 311   0   4
    7  11]
 [ 11   5   3   2   1   4   1  22   8   8   2  16   8  11   6  11 219   5
   13   8]
 [ 27   2   1   0   1   3   2  10   9   9   2   3   4   4   5   9  10 261
   12   2]
 [ 14   1   0   0   0   2   3  16   6   6   4   8   6  12   8   7  92  11
  103  11]
 [ 50   2   3   0   2   0   1  17   6   2   1   3   2  11   4  82  24   8
    6  27]]

================================================================================
SGDClassifier Elastic-Net penalty
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',
              power_t=0.5, random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 3.035s
test time:  0.024s
accuracy:   0.690
dimensionality: 101322
density: 0.033107

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.53      0.47      0.50       319
           comp.graphics       0.65      0.72      0.68       389
 comp.os.ms-windows.misc       0.65      0.63      0.64       394
comp.sys.ibm.pc.hardware       0.68      0.65      0.66       392
   comp.sys.mac.hardware       0.73      0.69      0.71       385
          comp.windows.x       0.80      0.71      0.75       395
            misc.forsale       0.74      0.79      0.77       390
               rec.autos       0.78      0.70      0.74       396
         rec.motorcycles       0.51      0.79      0.62       398
      rec.sport.baseball       0.80      0.82      0.81       397
        rec.sport.hockey       0.86      0.89      0.87       399
               sci.crypt       0.81      0.71      0.76       396
         sci.electronics       0.61      0.53      0.57       393
                 sci.med       0.74      0.80      0.77       396
               sci.space       0.71      0.77      0.73       394
  soc.religion.christian       0.64      0.81      0.72       398
      talk.politics.guns       0.56      0.65      0.60       364
   talk.politics.mideast       0.84      0.76      0.80       376
      talk.politics.misc       0.59      0.44      0.50       310
      talk.religion.misc       0.55      0.19      0.28       251

                accuracy                           0.69      7532
               macro avg       0.69      0.68      0.67      7532
            weighted avg       0.69      0.69      0.69      7532

confusion matrix:
[[149   2   2   1   1   1   7   6  11   2   6   4   5   9  16  61   6  12
    5  13]
 [  3 280  21  11   6  21   5   1   8   4   1   8   6   2   9   1   0   1
    0   1]
 [  5  20 248  29  13  15   2   2  17   2   2   4   1   9  10   1   5   1
    7   1]
 [  0  13  34 253  26   4  13   1   8   3   2   6  25   0   1   1   1   0
    1   0]
 [  2   8   8  22 267   7  15   2  16   3   0   3  16   6   4   1   4   0
    1   0]
 [  1  43  32   4   6 280   1   0   9   1   0   2   3   0  10   0   2   1
    0   0]
 [  0   2   2  12  13   0 310   7   9   4   2   1  11   3   5   1   4   1
    3   0]
 [  3   3   1   0   3   0  13 277  46   5   2   1  20   2   6   0   6   4
    3   1]
 [  2   3   2   2   2   0   5  20 315   8   3   0  11   6   8   2   3   0
    5   1]
 [  1   3   0   0   0   0   4   3  23 327  19   0   1   3   0   4   1   2
    6   0]
 [  0   1   2   1   2   0   0   2  13  12 354   0   0   4   0   2   4   0
    1   1]
 [  1   8   5   4   6   3   6   2  23   4   1 282   9   5   4   5  18   4
    4   2]
 [  6  17   8  30  12   7  17   9  18   8   4  16 210  13  11   2   2   1
    2   0]
 [  7   8   2   0   0   0   6   2  19   1   5   1   4 317   5   7   3   3
    5   1]
 [  4  14   2   1   1   1   3   5  22   5   5   1   8   7 302   1   3   1
    8   0]
 [ 22   2   2   0   1   1   2   0  16   4   0   1   3   6   4 324   1   2
    4   3]
 [  5   3   5   2   4   3   4   3  16   4   1   9   1  12  11  10 238   6
   20   7]
 [ 24   1   1   1   1   1   2   3   9   7   1   3   1   3   3   6  11 284
   12   2]
 [ 11   0   0   0   2   1   2   5  13   5   5   5   5   8  11   2  90   5
  135   5]
 [ 36   3   3   1   0   3   3   4   9   2   1   1   2  13   8  76  22   9
    8  47]]

================================================================================
NearestCentroid (aka Rocchio classifier)
________________________________________________________________________________
Training: 
NearestCentroid(metric='euclidean', shrink_threshold=None)
train time: 0.038s
test time:  0.028s
accuracy:   0.643
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.39      0.43      0.41       319
           comp.graphics       0.54      0.70      0.61       389
 comp.os.ms-windows.misc       0.68      0.60      0.64       394
comp.sys.ibm.pc.hardware       0.64      0.59      0.61       392
   comp.sys.mac.hardware       0.78      0.64      0.70       385
          comp.windows.x       0.87      0.64      0.73       395
            misc.forsale       0.82      0.73      0.77       390
               rec.autos       0.75      0.71      0.73       396
         rec.motorcycles       0.69      0.72      0.71       398
      rec.sport.baseball       0.88      0.78      0.83       397
        rec.sport.hockey       0.96      0.80      0.87       399
               sci.crypt       0.94      0.56      0.70       396
         sci.electronics       0.27      0.69      0.39       393
                 sci.med       0.92      0.57      0.70       396
               sci.space       0.75      0.71      0.73       394
  soc.religion.christian       0.68      0.67      0.67       398
      talk.politics.guns       0.58      0.63      0.61       364
   talk.politics.mideast       0.95      0.67      0.78       376
      talk.politics.misc       0.41      0.50      0.45       310
      talk.religion.misc       0.34      0.31      0.33       251

                accuracy                           0.64      7532
               macro avg       0.69      0.63      0.65      7532
            weighted avg       0.71      0.64      0.66      7532

confusion matrix:
[[137   5   0   0   0   1   0   2  10   3   0   1  30   0  14  53   7   4
    9  43]
 [  9 273  20   9   6  14   3   0   6   2   0   0  34   0   9   0   0   0
    3   1]
 [  7  33 237  32  14  10   0   3   3   1   0   1  30   1   8   0   1   0
    8   5]
 [  1  23  35 230  19   4   8   3   0   0   0   1  63   0   1   0   0   0
    3   1]
 [  1  12   9  32 245   1   8   2   3   1   1   0  60   2   3   0   1   0
    2   2]
 [  0  55  27   7   3 251   1   2   2   1   0   0  34   0   5   0   0   0
    6   1]
 [  1   4   3  24  11   1 286  12   3   1   0   1  36   0   3   1   0   0
    3   0]
 [  5   1   1   0   0   0   8 283  24   0   0   0  59   0   4   0   4   0
    5   2]
 [  7   0   0   1   0   0   6  30 288   4   0   0  35   2   3   2   5   0
   14   1]
 [  8   6   0   0   0   1   4   3   6 311  13   0  32   1   1   0   1   1
    8   1]
 [  7   1   0   0   0   0   0   2   8  19 321   0  23   2   2   0   3   0
    7   4]
 [  3  18   2   3   5   2   1   1   4   1   0 220  63   1   6   0  32   1
   25   8]
 [  3  24   9  22  10   1   8  10   6   2   0   7 273   4   7   1   1   0
    3   2]
 [ 11  25   0   0   0   0   8  10  14   1   0   0  71 224   4   5   1   1
   19   2]
 [  9  10   1   0   1   0   3   4   8   1   1   0  54   2 280   0   2   0
   18   0]
 [ 29   7   1   0   0   0   2   0   1   0   0   0  32   1   5 265   2   0
   10  43]
 [ 13   1   0   0   0   1   1   4  12   0   0   2  29   0   3   5 231   2
   41  19]
 [ 36   2   0   0   0   0   1   0  11   3   0   0  19   1   2   3   9 251
   28  10]
 [ 21   2   0   0   0   1   0   2   2   2   0   0  21   0   8   3  81   0
  156  11]
 [ 46   2   1   0   0   0   1   3   7   0   0   0  18   2   5  53  18   5
   11  79]]

================================================================================
Naive Bayes
________________________________________________________________________________
Training: 
MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)
train time: 0.134s
test time:  0.026s
accuracy:   0.696
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.56      0.43      0.49       319
           comp.graphics       0.65      0.71      0.68       389
 comp.os.ms-windows.misc       0.75      0.46      0.57       394
comp.sys.ibm.pc.hardware       0.59      0.72      0.65       392
   comp.sys.mac.hardware       0.71      0.69      0.70       385
          comp.windows.x       0.79      0.75      0.77       395
            misc.forsale       0.81      0.72      0.76       390
               rec.autos       0.76      0.72      0.74       396
         rec.motorcycles       0.76      0.73      0.74       398
      rec.sport.baseball       0.94      0.81      0.87       397
        rec.sport.hockey       0.59      0.93      0.72       399
               sci.crypt       0.72      0.76      0.74       396
         sci.electronics       0.74      0.60      0.66       393
                 sci.med       0.84      0.77      0.80       396
               sci.space       0.75      0.80      0.78       394
  soc.religion.christian       0.59      0.86      0.70       398
      talk.politics.guns       0.56      0.72      0.63       364
   talk.politics.mideast       0.81      0.80      0.80       376
      talk.politics.misc       0.56      0.44      0.49       310
      talk.religion.misc       0.47      0.21      0.29       251

                accuracy                           0.70      7532
               macro avg       0.70      0.68      0.68      7532
            weighted avg       0.70      0.70      0.69      7532

confusion matrix:
[[138   1   2   2   2   2   0   3   3   2  12   3   0   3  10  74  13  12
   12  25]
 [  2 278   6  17  15  24   6   0   5   3   6  13   2   0   9   2   0   1
    0   0]
 [  4  30 181  73  16  30   4   2   5   0  16  12   3   2   8   1   0   1
    3   3]
 [  0  13  20 284  29   4  10   2   0   0   8   5  16   0   0   0   0   0
    1   0]
 [  0  11   8  32 265   5   8   7   2   0  14   7  13   2   6   2   1   1
    1   0]
 [  0  46   9   9   7 297   1   0   0   1   7   5   5   3   4   0   1   0
    0   0]
 [  1   4   1  32  18   0 281  14   7   3  11   1   7   2   4   1   1   0
    2   0]
 [  1   1   1   1   1   0   9 285  31   1  25   4  10   1   6   3   4   3
    9   0]
 [  8   3   1   0   2   3   7  26 290   1  15   0   8   3   6   3  11   3
    7   1]
 [  5   2   0   0   0   1   6   0   4 322  34   4   1   3   2   3   5   1
    4   0]
 [  5   0   0   0   0   1   0   1   3   3 373   3   0   2   2   4   2   0
    0   0]
 [  1   9   6   3   4   2   1   0   3   2  18 301   3   1   5   3  20   4
    9   1]
 [  1  11   6  27  12   0  10  11   6   1  11  33 237  11  10   2   0   2
    2   0]
 [  4   5   0   1   0   0   3   7   4   0  15   0   5 304  11  17   9   4
    5   2]
 [  4   6   1   1   0   2   1   6   2   1  18   2   5   4 317   5   3   7
    8   1]
 [  8   3   0   1   1   2   0   1   1   1  15   1   0   2   1 343   4   0
    3  11]
 [  5   0   0   0   0   1   1   3   5   1  12  11   1   5   8  11 262   8
   16  14]
 [ 11   3   0   1   0   1   0   2   4   2   9   2   0   0   1  14  10 299
   17   0]
 [ 14   2   0   0   0   3   1   4   3   0   8   6   2   7   8   8  94  12
  136   2]
 [ 34   3   0   1   0   0   0   2   4   0   8   4   2   7   5  87  25   9
    7  53]]

________________________________________________________________________________
Training: 
BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)
train time: 0.142s
test time:  0.131s
accuracy:   0.567
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.39      0.49      0.43       319
           comp.graphics       0.54      0.64      0.59       389
 comp.os.ms-windows.misc       0.38      0.01      0.01       394
comp.sys.ibm.pc.hardware       0.48      0.70      0.57       392
   comp.sys.mac.hardware       0.29      0.79      0.42       385
          comp.windows.x       0.82      0.55      0.65       395
            misc.forsale       0.80      0.67      0.73       390
               rec.autos       0.48      0.70      0.57       396
         rec.motorcycles       0.37      0.78      0.50       398
      rec.sport.baseball       0.77      0.79      0.78       397
        rec.sport.hockey       0.97      0.70      0.82       399
               sci.crypt       0.79      0.50      0.61       396
         sci.electronics       0.58      0.57      0.58       393
                 sci.med       0.86      0.57      0.68       396
               sci.space       0.79      0.54      0.64       394
  soc.religion.christian       0.70      0.62      0.66       398
      talk.politics.guns       0.63      0.46      0.53       364
   talk.politics.mideast       0.91      0.53      0.67       376
      talk.politics.misc       0.54      0.34      0.42       310
      talk.religion.misc       0.33      0.20      0.25       251

                accuracy                           0.57      7532
               macro avg       0.62      0.56      0.56      7532
            weighted avg       0.63      0.57      0.56      7532

confusion matrix:
[[155   1   0   1  25   0   4  16  27   7   0   2   4   1   3  34   2   5
    8  24]
 [  1 248   0  24  58  13   3   4   9   0   0   8   8   3   7   1   0   1
    1   0]
 [  3  61   3 139 103  29   4   9  13   0   0   9   7   4   7   1   0   0
    0   2]
 [  0   9   2 273  74   2   7   2   3   0   0   4  16   0   0   0   0   0
    0   0]
 [  0   7   1  27 303   0   6   9   7   0   0   2  15   0   8   0   0   0
    0   0]
 [  0  70   1  18  56 216   2   3  18   1   0   3   5   2   0   0   0   0
    0   0]
 [  0   1   0  29  52   1 260  15  13   3   1   0   6   2   4   2   0   1
    0   0]
 [  1   3   0   1  34   0   6 276  57   1   0   1   9   1   1   1   1   0
    2   1]
 [  2   1   0   0  28   0   3  33 309   2   0   1  11   0   0   0   4   1
    2   1]
 [  6   2   0   2  22   0   1   7  17 314   6   0   3   1   0   1   5   0
   10   0]
 [  2   1   1   0  25   0   2  10  25  44 281   1   2   1   1   0   1   0
    2   0]
 [ 15   9   0  10  51   1   3  21  42   5   0 199  19   1   6   0   6   1
    6   1]
 [  2  15   0  27  49   1   8  19  21   3   0  14 224   7   2   0   0   0
    1   0]
 [ 11   5   0   7  40   0   5  29  35   1   0   0  19 226   6   4   1   2
    4   1]
 [ 10  15   0   2  29   2   5  34  41   3   0   0  24   5 212   2   1   1
    8   0]
 [ 56   6   0   1  23   0   2   6  24   2   0   0   2   1   0 246   2   0
    3  24]
 [ 17   0   0   1  27   0   1  32  59   3   1   3   3   2   1   2 167   3
   21  21]
 [ 48   0   0   1  16   0   2  10  34   9   0   2   4   0   1  10   6 201
   20  12]
 [ 24   1   0   1  15   0   2  25  37   7   0   1   2   3   6   3  59   3
  106  15]
 [ 49   1   0   1  19   0   0  18  38   4   0   2   3   4   3  43  10   3
    2  51]]

________________________________________________________________________________
Training: 
ComplementNB(alpha=0.1, class_prior=None, fit_prior=True, norm=False)
train time: 0.144s
test time:  0.022s
accuracy:   0.708
dimensionality: 101322
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.32      0.45      0.37       319
           comp.graphics       0.72      0.70      0.71       389
 comp.os.ms-windows.misc       0.73      0.52      0.61       394
comp.sys.ibm.pc.hardware       0.64      0.68      0.66       392
   comp.sys.mac.hardware       0.77      0.71      0.74       385
          comp.windows.x       0.77      0.80      0.79       395
            misc.forsale       0.74      0.72      0.73       390
               rec.autos       0.78      0.75      0.77       396
         rec.motorcycles       0.80      0.77      0.78       398
      rec.sport.baseball       0.90      0.85      0.87       397
        rec.sport.hockey       0.86      0.95      0.90       399
               sci.crypt       0.76      0.80      0.78       396
         sci.electronics       0.72      0.56      0.63       393
                 sci.med       0.76      0.80      0.78       396
               sci.space       0.77      0.80      0.78       394
  soc.religion.christian       0.58      0.88      0.70       398
      talk.politics.guns       0.60      0.68      0.64       364
   talk.politics.mideast       0.76      0.84      0.80       376
      talk.politics.misc       0.67      0.42      0.52       310
      talk.religion.misc       0.48      0.17      0.25       251

                accuracy                           0.71      7532
               macro avg       0.71      0.69      0.69      7532
            weighted avg       0.71      0.71      0.70      7532

confusion matrix:
[[143   0   3   2   2   2   2   2   1   2   8   4   3   6  12  81   9  19
    5  13]
 [ 10 274  11  13   6  31   8   1   3   3   0  12   4   0   6   1   1   3
    1   1]
 [ 22  23 206  52  11  27   9   2   4   0   2   4   4   5  10   4   1   1
    5   2]
 [  7  11  22 268  24   8  16   1   0   1   2   8  20   0   2   0   1   0
    1   0]
 [ 14   5   8  16 274  10  17   8   1   1   0   4  13   3   4   2   3   0
    0   2]
 [  7  34   8   2   4 316   1   0   0   1   3   3   2   4   4   0   4   1
    0   1]
 [  8   0   0  32  15   2 282  13   9   5   2   1   9   2   4   2   2   0
    2   0]
 [ 25   4   2   0   2   1   8 297  24   0   1   1   8   2   7   2   2   3
    4   3]
 [ 17   3   1   2   2   0   6  19 305   5   7   2   3   6   7   2   4   3
    2   2]
 [ 21   2   0   0   0   0   4   0   4 337  15   0   1   4   0   4   1   0
    4   0]
 [ 12   0   0   0   0   0   0   0   1   2 379   2   0   1   0   2   0   0
    0   0]
 [ 17   5   5   1   3   2   3   2   1   1   0 317   4   2   4   4  15   6
    2   2]
 [ 12   6   9  28  10   2  13  11   8   0   4  30 219  19  10   3   1   5
    3   0]
 [ 19   4   0   2   0   0   2   4   1   4   5   2   5 316   5  10   8   5
    3   1]
 [ 23   4   1   0   1   3   3   6   4   3   1   1   2   6 316   2   2  10
    4   2]
 [ 22   2   0   0   0   1   0   1   1   2   0   0   1   4   1 351   0   1
    5   6]
 [ 13   2   3   1   0   0   2   5   5   2   4  11   1  13   8  15 248  15
   11   5]
 [ 10   1   0   1   1   1   2   1   5   3   2   2   1   1   0  11   8 315
    8   3]
 [ 19   0   1   0   0   2   2   5   0   2   4  11   1  12   7  11  81  18
  130   4]
 [ 30   2   2   1   0   1   2   2   3   1   1   2   2  12   6 102  25  11
    3  43]]

================================================================================
LinearSVC with L1-based feature selection

Process finished with exit code 0
