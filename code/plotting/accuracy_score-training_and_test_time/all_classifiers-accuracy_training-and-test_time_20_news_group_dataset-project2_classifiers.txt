/home/ramon/virtual_envs/comp551_p2/bin/python /home/ramon/github/comp551-2020-p2_classification_of_textual_data/code/classification_of_text_documents.py --all_categories --report --confusion_matrix --plot_training_and_test_time_together_with_accuracy_score

##########################################################
# Classification of text documents using sparse features
##########################################################

This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.

The dataset used in this example is the 20 newsgroups dataset. It will be automatically downloaded, then cached.

https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py

Usage: classification_of_text_documents.py [options]

Options:
  -h, --help            show this help message and exit
  --report              Print a detailed classification report.
  --chi2_select=SELECT_CHI2
                        Select some number of features using a chi-squared
                        test
  --confusion_matrix    Print the confusion matrix.
  --top10               Print ten most discriminative terms per class for
                        every classifier.
  --all_categories      Whether to use all categories or not.
  --use_hashing         Use a hashing vectorizer.
  --n_features=N_FEATURES
                        n_features when using the hashing vectorizer.
  --filtered            Remove newsgroup information that is easily overfit:
                        headers, signatures, and quoting.
  --just_miniproject_classifiers
                        Use just the miniproject classifiers (1.
                        LogisticRegression, 2. DecisionTreeClassifier, 3.
                        LinearSVC (L1), 4. LinearSVC (L2), 5.
                        AdaBoostClassifier, 6. RandomForestClassifier)
  --plot_training_and_test_time_together_with_accuracy_score
                        Plot training time and test time together with
                        accuracy score

Loading 20 newsgroups dataset for categories:
all
data loaded
11314 documents - 22.055MB (training set)
7532 documents - 13.801MB (test set)
20 categories

Extracting features from the training data using a sparse vectorizer
done in 3.101065s at 7.112MB/s
n_samples: 11314, n_features: 129791

Extracting features from the test data using the same vectorizer
done in 1.866778s at 7.393MB/s
n_samples: 7532, n_features: 129791

================================================================================
Ridge Classifier
________________________________________________________________________________
Training: 
RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize=False, random_state=None, solver='sag',
                tol=0.01)
/home/ramon/virtual_envs/comp551_p2/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:558: UserWarning: "sag" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to "auto" or "sparse_cg", or set a low "tol" and a high "max_iter" (especially if inputs are not standardized).
  '"sag" solver requires many iterations to fit '
train time: 6.878s
test time:  0.036s
accuracy:   0.862
dimensionality: 129791
density: 0.999998

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.82      0.78      0.80       319
           comp.graphics       0.76      0.83      0.79       389
 comp.os.ms-windows.misc       0.80      0.79      0.79       394
comp.sys.ibm.pc.hardware       0.73      0.78      0.76       392
   comp.sys.mac.hardware       0.83      0.86      0.85       385
          comp.windows.x       0.89      0.79      0.84       395
            misc.forsale       0.85      0.91      0.88       390
               rec.autos       0.93      0.92      0.92       396
         rec.motorcycles       0.96      0.95      0.96       398
      rec.sport.baseball       0.91      0.95      0.93       397
        rec.sport.hockey       0.96      0.98      0.97       399
               sci.crypt       0.95      0.95      0.95       396
         sci.electronics       0.81      0.77      0.79       393
                 sci.med       0.91      0.88      0.90       396
               sci.space       0.90      0.93      0.91       394
  soc.religion.christian       0.85      0.94      0.89       398
      talk.politics.guns       0.75      0.94      0.83       364
   talk.politics.mideast       0.98      0.90      0.94       376
      talk.politics.misc       0.86      0.61      0.71       310
      talk.religion.misc       0.78      0.63      0.70       251

                accuracy                           0.86      7532
               macro avg       0.86      0.85      0.86      7532
            weighted avg       0.86      0.86      0.86      7532

confusion matrix:
[[248   1   0   2   0   0   1   0   2   0   0   1   1   9   7  25   0   1
    0  21]
 [  2 321   9   8   6  15   3   0   1   2   1   3  10   0   5   1   0   0
    0   2]
 [  0  16 312  28  11  10   1   1   0   5   1   1   1   1   3   0   0   0
    0   3]
 [  0  11  23 306  18   1  10   2   0   2   0   0  17   0   1   0   0   0
    0   1]
 [  0   5   4  21 333   1   9   0   0   1   0   0   8   2   0   0   1   0
    0   0]
 [  0  36  30   3   3 312   3   0   1   0   0   1   0   1   4   0   1   0
    0   0]
 [  0   2   1   9   7   0 353   5   2   1   0   1   7   1   1   0   0   0
    0   0]
 [  0   2   0   4   1   1   8 363   4   2   0   0   7   1   0   0   1   0
    2   0]
 [  0   0   0   1   0   0   3   8 380   1   0   0   3   1   0   0   0   0
    0   1]
 [  0   0   1   0   0   1   4   1   1 376  12   0   1   0   0   0   0   0
    0   0]
 [  0   0   0   0   1   1   0   0   0   5 391   0   0   0   0   1   0   0
    0   0]
 [  0   3   2   0   3   1   3   2   0   2   0 377   2   0   0   0   1   0
    0   0]
 [  0   5   6  28  11   2   5   7   3   2   1   5 303   5   5   5   0   0
    0   0]
 [  1   5   0   4   2   2   5   1   1   4   1   0   6 350   1   3   2   2
    5   1]
 [  1  10   0   0   1   3   2   0   0   0   0   1   4   4 366   0   0   0
    2   0]
 [  3   0   2   1   0   0   0   0   0   1   0   0   2   3   3 374   0   0
    0   9]
 [  0   1   0   1   1   0   2   1   0   1   0   2   0   1   0   0 342   1
    9   2]
 [ 10   2   0   0   1   2   0   1   0   5   1   0   0   1   1   6   1 339
    6   0]
 [  3   1   0   0   2   0   1   0   0   0   0   3   0   4   6   1  95   1
  188   5]
 [ 33   2   1   1   0   0   1   0   0   1   0   0   0   2   5  26  12   1
    7 159]]

================================================================================
Perceptron
________________________________________________________________________________
Training: 
Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,
           fit_intercept=True, max_iter=50, n_iter_no_change=5, n_jobs=None,
           penalty=None, random_state=0, shuffle=True, tol=0.001,
           validation_fraction=0.1, verbose=0, warm_start=False)
train time: 1.386s
test time:  0.050s
accuracy:   0.816
dimensionality: 129791
density: 0.094928

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.82      0.73      0.77       319
           comp.graphics       0.69      0.78      0.73       389
 comp.os.ms-windows.misc       0.75      0.69      0.72       394
comp.sys.ibm.pc.hardware       0.77      0.69      0.73       392
   comp.sys.mac.hardware       0.80      0.81      0.80       385
          comp.windows.x       0.81      0.73      0.77       395
            misc.forsale       0.82      0.87      0.84       390
               rec.autos       0.88      0.85      0.87       396
         rec.motorcycles       0.88      0.94      0.91       398
      rec.sport.baseball       0.89      0.90      0.90       397
        rec.sport.hockey       0.91      0.96      0.94       399
               sci.crypt       0.85      0.93      0.89       396
         sci.electronics       0.77      0.69      0.73       393
                 sci.med       0.77      0.81      0.79       396
               sci.space       0.88      0.90      0.89       394
  soc.religion.christian       0.85      0.91      0.88       398
      talk.politics.guns       0.75      0.87      0.81       364
   talk.politics.mideast       0.89      0.85      0.87       376
      talk.politics.misc       0.80      0.62      0.70       310
      talk.religion.misc       0.67      0.65      0.66       251

                accuracy                           0.82      7532
               macro avg       0.81      0.81      0.81      7532
            weighted avg       0.82      0.82      0.81      7532

confusion matrix:
[[232   4   0   1   0   0   1   1   6   0   0   1   1  10  10  14   1   3
    1  33]
 [  1 305   8   4   5  13   3   3   1   1   4   9   7   7   4   3   2   3
    4   2]
 [  0  24 270  25  16  13   3   2   4   2   1   5   4  12   6   1   0   1
    0   5]
 [  0  14  27 271  19   2  13   3   1   1   0   4  25   5   0   1   2   1
    3   0]
 [  0   8   3  11 313   3  12   0   3   5   1   2  10   6   0   2   3   1
    1   1]
 [  0  45  31   3   4 289   5   4   1   1   0   3   0   5   4   0   0   0
    0   0]
 [  0   4   2   9   8   0 338   5   6   4   1   0   6   2   2   2   0   1
    0   0]
 [  2   1   3   1   0   2   9 338  11   3   2   2  10   2   0   1   3   3
    3   0]
 [  0   0   0   0   2   1   2   7 374   1   1   0   3   2   0   1   0   2
    1   1]
 [  1   0   0   1   3   4   6   2   1 359  11   1   0   2   1   1   2   1
    1   0]
 [  0   1   0   0   3   2   0   0   0   5 385   0   0   0   0   0   1   2
    0   0]
 [  0   3   2   0   3   2   2   0   1   2   1 368   1   2   0   0   4   2
    2   1]
 [  4   7   7  21   8   6   6   7   6   2   3  19 271  10   4   4   2   3
    0   3]
 [  2   7   2   4   4   7   5   4   2   5   4   1   9 321   2   5   1   4
    5   2]
 [  0  10   0   0   3   1   1   1   1   0   0   4   5   8 353   2   1   2
    2   0]
 [  2   2   0   0   0   1   0   2   0   1   0   0   1   3   4 363   1   1
    1  16]
 [  2   2   1   0   1   1   1   0   2   2   1   5   0   6   1   0 318   4
   11   6]
 [ 13   1   0   0   0   7   1   1   1   3   2   2   0   0   1   7   8 321
    7   1]
 [  2   2   2   0   1   1   2   3   3   4   4   5   1   5   6   1  61   3
  193  11]
 [ 22   5   2   1   0   1   2   2   0   1   0   1   0   7   3  21  12   1
    6 164]]

================================================================================
Passive-Aggressive
________________________________________________________________________________
Training: 
PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,
                            early_stopping=False, fit_intercept=True,
                            loss='hinge', max_iter=50, n_iter_no_change=5,
                            n_jobs=None, random_state=None, shuffle=True,
                            tol=0.001, validation_fraction=0.1, verbose=0,
                            warm_start=False)
train time: 2.034s
test time:  0.035s
accuracy:   0.856
dimensionality: 129791
density: 0.452816

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.81      0.80      0.80       319
           comp.graphics       0.78      0.82      0.80       389
 comp.os.ms-windows.misc       0.78      0.75      0.76       394
comp.sys.ibm.pc.hardware       0.72      0.73      0.72       392
   comp.sys.mac.hardware       0.82      0.85      0.83       385
          comp.windows.x       0.87      0.80      0.83       395
            misc.forsale       0.84      0.92      0.88       390
               rec.autos       0.94      0.91      0.92       396
         rec.motorcycles       0.96      0.97      0.96       398
      rec.sport.baseball       0.93      0.94      0.93       397
        rec.sport.hockey       0.95      0.98      0.97       399
               sci.crypt       0.91      0.94      0.93       396
         sci.electronics       0.79      0.77      0.78       393
                 sci.med       0.90      0.88      0.89       396
               sci.space       0.90      0.93      0.91       394
  soc.religion.christian       0.87      0.93      0.90       398
      talk.politics.guns       0.74      0.91      0.82       364
   talk.politics.mideast       0.97      0.89      0.93       376
      talk.politics.misc       0.84      0.61      0.71       310
      talk.religion.misc       0.75      0.66      0.70       251

                accuracy                           0.86      7532
               macro avg       0.85      0.85      0.85      7532
            weighted avg       0.86      0.86      0.85      7532

confusion matrix:
[[254   2   0   3   0   0   1   0   0   0   0   1   1   6   7  21   0   1
    0  22]
 [  2 320   7   7   7  15   4   1   0   3   1   6   7   1   4   2   0   0
    0   2]
 [  0  19 294  37   8  12   2   1   1   3   1   2   4   2   6   0   0   0
    0   2]
 [  0   9  25 285  25   5  13   1   0   1   0   2  25   0   1   0   0   0
    0   0]
 [  0   5   4  15 328   2  13   1   0   2   1   0   9   2   0   0   2   0
    1   0]
 [  0  32  30   5   3 315   4   0   0   0   0   0   0   2   3   0   1   0
    0   0]
 [  0   0   1   5   9   0 358   6   2   0   0   1   6   1   0   0   0   0
    1   0]
 [  0   1   1   4   0   1  10 360   6   2   0   0   7   1   0   0   1   0
    2   0]
 [  0   0   0   1   0   0   3   2 386   1   0   0   2   0   1   0   1   0
    0   1]
 [  0   0   1   0   0   1   4   1   1 374  12   0   0   1   0   0   0   0
    2   0]
 [  0   0   0   0   1   1   0   0   0   3 393   0   0   0   0   0   1   0
    0   0]
 [  0   2   2   0   3   1   2   2   1   2   1 374   1   1   0   0   2   1
    0   1]
 [  0   4   6  31   9   1   3   4   3   1   1  13 302   7   3   1   1   1
    1   1]
 [  2   4   0   3   2   3   4   2   1   4   0   0  10 348   1   2   2   2
    5   1]
 [  2   7   0   0   1   3   2   0   0   0   1   1   4   6 365   0   0   0
    2   0]
 [  3   0   2   0   0   0   1   0   0   1   0   0   2   1   3 372   0   0
    0  13]
 [  0   2   1   1   1   0   1   1   1   2   0   5   0   2   1   0 331   1
   10   4]
 [ 17   2   1   0   0   2   0   1   0   3   1   1   0   0   1   6   2 333
    6   0]
 [  3   1   0   0   4   1   0   0   0   0   1   3   0   4   5   1  88   2
  190   7]
 [ 30   1   2   1   0   0   1   1   0   1   0   0   0   3   4  23  13   1
    5 165]]

================================================================================
kNN
________________________________________________________________________________
Training: 
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,
                     weights='uniform')
train time: 0.005s
test time:  5.012s
accuracy:   0.717
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.68      0.80      0.73       319
           comp.graphics       0.56      0.65      0.60       389
 comp.os.ms-windows.misc       0.62      0.67      0.64       394
comp.sys.ibm.pc.hardware       0.54      0.63      0.58       392
   comp.sys.mac.hardware       0.62      0.62      0.62       385
          comp.windows.x       0.72      0.66      0.69       395
            misc.forsale       0.58      0.54      0.56       390
               rec.autos       0.77      0.73      0.75       396
         rec.motorcycles       0.84      0.86      0.85       398
      rec.sport.baseball       0.74      0.80      0.77       397
        rec.sport.hockey       0.83      0.89      0.86       399
               sci.crypt       0.81      0.86      0.83       396
         sci.electronics       0.66      0.53      0.59       393
                 sci.med       0.81      0.59      0.68       396
               sci.space       0.75      0.81      0.78       394
  soc.religion.christian       0.80      0.82      0.81       398
      talk.politics.guns       0.75      0.78      0.77       364
   talk.politics.mideast       0.87      0.85      0.86       376
      talk.politics.misc       0.74      0.65      0.70       310
      talk.religion.misc       0.67      0.57      0.61       251

                accuracy                           0.72      7532
               macro avg       0.72      0.71      0.71      7532
            weighted avg       0.72      0.72      0.72      7532

confusion matrix:
[[255   1   1   4   0   2   1   0   1   1   0   2   1   9   7  16   0   0
    0  18]
 [  6 251  20  12   9  23   6   6   4   8   6   8   7   2   9   1   4   3
    3   1]
 [  4  23 263  32   7  14  11   4   1   9   0   6   3   1   8   2   1   1
    2   2]
 [  3  20  31 246  22   8  19   2   2   2   0   4  17   1   9   0   0   1
    3   2]
 [  4  14  16  35 237   5  20   5   3   9   4   4   7   3   5   3   0   5
    4   2]
 [  2  37  30  10  12 259   6   1   8   4   2   4   8   2   9   0   0   1
    0   0]
 [  5  10  21  33  33   9 210   9   2  12   4   0  18   6   2   3   0   4
    4   5]
 [  0  10   5  14  13   7  12 291   7   4   3   4   8   4   1   1   7   2
    1   2]
 [  0   1   0   4   5   3   9  13 342   3   1   2   4   1   1   1   2   2
    3   1]
 [  7   6   0   3   3   0   7  12   3 318  24   1   2   0   2   0   3   2
    3   1]
 [  4   1   1   3   1   3   5   0   3  12 354   1   2   3   2   0   0   1
    0   3]
 [  4   4   3   4   7   2   2   2   3   2   3 339   1   3   3   3   6   1
    4   0]
 [  8  19  15  24  15   3  18  12  11  11   7  10 209   7  11   2   1   4
    2   4]
 [  8   9   7  11   9   4  23   4   9  10   5   7  17 233   2  11   2   9
    9   7]
 [  1  20   3   4   0   3   3   7   1   7   3   4   6   3 318   0   6   1
    4   0]
 [ 16   2   3   1   1   3   2   1   2   3   4   1   1   2   6 328   2   1
    6  13]
 [  0   4   2   6   2   5   1   4   4   5   0  12   1   2   9   2 285   3
   11   6]
 [  5   4   1   1   3   1   0   1   1   2   5   2   3   1   2  18   1 320
    5   0]
 [  1   8   2   2   2   2   8   3   0   1   3   8   0   0  10   1  48   3
  203   5]
 [ 42   2   1   3   2   2   1   2   0   5   1   1   1   3   6  16  11   2
    7 143]]

================================================================================
Logistic Regression
________________________________________________________________________________
Training: 
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
train time: 62.942s
test time:  0.035s
accuracy:   0.845
dimensionality: 129791
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.80      0.74      0.77       319
           comp.graphics       0.71      0.82      0.76       389
 comp.os.ms-windows.misc       0.77      0.79      0.78       394
comp.sys.ibm.pc.hardware       0.72      0.75      0.74       392
   comp.sys.mac.hardware       0.83      0.85      0.84       385
          comp.windows.x       0.86      0.77      0.81       395
            misc.forsale       0.82      0.88      0.85       390
               rec.autos       0.92      0.91      0.91       396
         rec.motorcycles       0.97      0.96      0.97       398
      rec.sport.baseball       0.93      0.94      0.94       397
        rec.sport.hockey       0.95      0.97      0.96       399
               sci.crypt       0.96      0.92      0.94       396
         sci.electronics       0.77      0.77      0.77       393
                 sci.med       0.88      0.87      0.88       396
               sci.space       0.89      0.93      0.91       394
  soc.religion.christian       0.81      0.93      0.87       398
      talk.politics.guns       0.74      0.91      0.82       364
   talk.politics.mideast       0.97      0.88      0.92       376
      talk.politics.misc       0.84      0.60      0.70       310
      talk.religion.misc       0.81      0.53      0.64       251

                accuracy                           0.85      7532
               macro avg       0.85      0.84      0.84      7532
            weighted avg       0.85      0.85      0.84      7532

confusion matrix:
[[236   2   0   1   1   0   1   0   1   2   0   1   3  10   4  36   0   5
    0  16]
 [  3 319  10   7   9  19   3   1   0   1   0   2   8   0   4   1   1   0
    0   1]
 [  0  19 310  31   8   9   1   1   1   3   1   1   1   1   3   0   0   0
    1   3]
 [  0  13  22 294  17   3  12   3   0   0   1   0  24   0   3   0   0   0
    0   0]
 [  0   3   7  20 326   1  13   0   1   3   0   0   9   0   2   0   0   0
    0   0]
 [  1  39  35   5   2 305   3   0   0   0   0   0   0   1   3   0   1   0
    0   0]
 [  0   4   2  14   9   0 344   6   0   0   2   0   7   2   0   0   0   0
    0   0]
 [  0   1   1   2   0   2  10 360   3   1   0   0  12   1   1   0   0   0
    2   0]
 [  0   0   0   1   0   0   5   7 383   1   0   0   1   0   0   0   0   0
    0   0]
 [  0   0   0   0   1   0   4   2   1 375  13   0   1   0   0   0   0   0
    0   0]
 [  0   1   0   0   4   0   1   0   0   5 386   0   0   0   1   1   0   0
    0   0]
 [  1   7   3   0   2   2   2   2   0   1   0 363   7   2   1   0   1   0
    2   0]
 [  0  13   9  27   9   2   8   5   2   2   0   4 304   3   5   0   0   0
    0   0]
 [  2   9   1   2   2   3   7   2   1   1   3   0  10 344   0   4   1   1
    3   0]
 [  0  11   0   0   1   1   2   0   0   0   0   0   1   8 367   1   0   0
    2   0]
 [  4   1   2   0   0   1   0   0   0   1   0   0   4   2   3 372   0   0
    1   7]
 [  0   1   0   2   1   0   3   3   1   2   0   5   1   4   2   0 330   1
    6   2]
 [ 12   2   0   0   0   8   0   1   0   3   1   0   0   2   1   2   1 332
   11   0]
 [  1   2   0   0   3   0   1   0   1   1   0   2   0   5   8   1  96   2
  185   2]
 [ 36   3   1   1   0   0   1   0   0   2   0   0   0   4   5  44  12   2
    8 132]]

================================================================================
Decision Tree Classifier
________________________________________________________________________________
Training: 
DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=None, splitter='best')
train time: 20.875s
test time:  0.017s
accuracy:   0.585
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.47      0.53      0.50       319
           comp.graphics       0.50      0.52      0.51       389
 comp.os.ms-windows.misc       0.57      0.58      0.57       394
comp.sys.ibm.pc.hardware       0.42      0.42      0.42       392
   comp.sys.mac.hardware       0.52      0.57      0.54       385
          comp.windows.x       0.58      0.53      0.55       395
            misc.forsale       0.63      0.74      0.68       390
               rec.autos       0.62      0.60      0.61       396
         rec.motorcycles       0.75      0.76      0.76       398
      rec.sport.baseball       0.59      0.59      0.59       397
        rec.sport.hockey       0.72      0.69      0.70       399
               sci.crypt       0.79      0.70      0.74       396
         sci.electronics       0.36      0.41      0.39       393
                 sci.med       0.55      0.48      0.51       396
               sci.space       0.73      0.67      0.70       394
  soc.religion.christian       0.73      0.76      0.74       398
      talk.politics.guns       0.54      0.64      0.59       364
   talk.politics.mideast       0.84      0.64      0.73       376
      talk.politics.misc       0.41      0.37      0.39       310
      talk.religion.misc       0.38      0.36      0.37       251

                accuracy                           0.59      7532
               macro avg       0.58      0.58      0.58      7532
            weighted avg       0.59      0.59      0.59      7532

confusion matrix:
[[168   8   1   2   3   4   2   2   2   3   3   4   8  16   7  22   8  10
    9  37]
 [  5 201  24  24  24  28  10   4   3   8   3  10  17   5   8   6   3   2
    3   1]
 [  8  25 229  39  17  23   8   3   3   4   3   6  10   4   2   2   4   2
    2   0]
 [  4  27  31 165  40  13  22   7   0   1   5   6  40  11   3   5   4   1
    2   5]
 [  1  15  10  32 221  10  23   2   3   4   4   2  25   5   8   1   7   1
    9   2]
 [  3  31  43  18  17 210   7   8   1   5   1   4  24   8   4   2   2   2
    3   2]
 [  2  10   3  17  13   1 287  14   5   3   2   1  15   6   1   0   3   0
    4   3]
 [  4   4   9   9   8   4  14 237  18   5   3   1  43  10   4   3  11   1
    4   4]
 [  5   3   2   9   5   3  13  18 304   5   1   2   4   8   1   1   6   1
    5   2]
 [ 10   7   6   5   9   4   9   8   9 234  45   3   5  10   7   0   4   1
   14   7]
 [  1   2   1   3  14   5   7   2   1  62 276   3   2   4   3   1   2   1
    4   5]
 [  6  11   4   8   7   4   6   3   8   2   0 277  19   6   4   2  13   2
   12   2]
 [  6  18  14  35  22  15  25  21  12   8   8  12 163  11   6   4   6   0
    3   4]
 [ 18  14   3  15  12  20   4  10   4  20   9   1  29 189   7   8   8   3
   13   9]
 [ 11   9   9   6   4   6   7   4   9   9   4   1  15   8 265   4   3   6
    9   5]
 [ 18  10   3   2   2   3   3   4   0   4   3   0   5   6   3 302   2   4
    7  17]
 [ 11   5   5   1   3   0   3  10   8   3   2   8   4   8   5   3 234   5
   30  16]
 [ 20   1   0   1   0   5   2   4   8  14   6   1   7   7   9  10   5 241
   18  17]
 [ 15   2   1   0   4   2   3  15   5   3   4   5   6  15   8   5  88   2
  114  13]
 [ 43   3   5   1   3   3   2   5   2   1   2   2   6   7   6  33  17   3
   16  91]]

================================================================================
Linear SVC (penalty = L2)
________________________________________________________________________________
Training: 
LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.001,
          verbose=0)
train time: 9.053s
test time:  0.060s
accuracy:   0.861
dimensionality: 129791
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.83      0.79      0.81       319
           comp.graphics       0.76      0.82      0.79       389
 comp.os.ms-windows.misc       0.80      0.77      0.79       394
comp.sys.ibm.pc.hardware       0.73      0.78      0.75       392
   comp.sys.mac.hardware       0.83      0.86      0.85       385
          comp.windows.x       0.88      0.78      0.83       395
            misc.forsale       0.84      0.91      0.87       390
               rec.autos       0.93      0.91      0.92       396
         rec.motorcycles       0.96      0.96      0.96       398
      rec.sport.baseball       0.92      0.95      0.94       397
        rec.sport.hockey       0.95      0.98      0.97       399
               sci.crypt       0.94      0.95      0.95       396
         sci.electronics       0.83      0.77      0.80       393
                 sci.med       0.92      0.88      0.90       396
               sci.space       0.90      0.94      0.92       394
  soc.religion.christian       0.86      0.94      0.90       398
      talk.politics.guns       0.74      0.92      0.82       364
   talk.politics.mideast       0.98      0.91      0.94       376
      talk.politics.misc       0.85      0.60      0.70       310
      talk.religion.misc       0.76      0.63      0.69       251

                accuracy                           0.86      7532
               macro avg       0.86      0.85      0.85      7532
            weighted avg       0.86      0.86      0.86      7532

confusion matrix:
[[251   1   0   2   0   0   1   0   2   0   0   1   1   7   8  21   0   1
    0  23]
 [  1 318   8   9   7  18   4   1   1   3   1   4   7   0   4   1   0   0
    0   2]
 [  0  19 304  33   9  11   1   0   1   3   1   1   2   2   4   0   0   0
    0   3]
 [  0  12  21 306  19   1  12   2   0   1   0   0  17   0   0   0   0   0
    0   1]
 [  0   5   4  15 333   1  11   1   0   2   0   0   9   1   0   0   2   0
    1   0]
 [  1  37  30   3   3 310   3   0   0   0   1   0   1   1   4   0   1   0
    0   0]
 [  0   1   1   6   8   0 356   6   2   1   0   1   6   1   0   0   0   0
    1   0]
 [  0   1   0   5   1   1  10 359   6   2   0   0   7   1   0   0   1   0
    2   0]
 [  0   0   0   1   0   0   4   6 383   1   0   0   0   0   1   0   1   0
    0   1]
 [  0   0   1   0   0   0   4   2   1 377  12   0   0   0   0   0   0   0
    0   0]
 [  0   0   0   0   1   1   0   0   0   5 391   0   0   0   0   1   0   0
    0   0]
 [  0   2   1   0   4   1   3   2   0   2   0 378   1   0   0   0   1   1
    0   0]
 [  0   6   5  33  11   0   3   4   3   1   0  10 304   6   3   2   0   0
    1   1]
 [  2   5   0   3   2   2   5   2   1   4   2   0   8 349   1   2   2   2
    3   1]
 [  1   6   0   0   1   3   2   0   0   0   1   1   3   4 369   0   1   0
    2   0]
 [  3   0   2   1   0   0   0   0   0   1   0   0   2   1   3 375   0   0
    0  10]
 [  0   2   1   1   1   0   2   1   0   1   0   3   0   1   1   0 336   1
   10   3]
 [  8   1   1   0   0   2   0   1   0   3   1   0   0   1   1   6   2 343
    6   0]
 [  3   1   0   0   2   0   2   0   0   0   0   4   0   4   6   1  94   2
  186   5]
 [ 31   2   1   1   0   0   1   1   0   1   0   0   0   2   3  29  13   1
    7 158]]

================================================================================
Linear SVC (penalty = L1)
________________________________________________________________________________
Training: 
LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l1', random_state=None, tol=0.001,
          verbose=0)
train time: 6.835s
test time:  0.035s
accuracy:   0.827
dimensionality: 129791
density: 0.002413

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.78      0.74      0.76       319
           comp.graphics       0.72      0.78      0.75       389
 comp.os.ms-windows.misc       0.76      0.77      0.76       394
comp.sys.ibm.pc.hardware       0.68      0.77      0.72       392
   comp.sys.mac.hardware       0.79      0.84      0.82       385
          comp.windows.x       0.89      0.75      0.81       395
            misc.forsale       0.83      0.87      0.85       390
               rec.autos       0.87      0.87      0.87       396
         rec.motorcycles       0.91      0.94      0.92       398
      rec.sport.baseball       0.91      0.92      0.92       397
        rec.sport.hockey       0.95      0.96      0.95       399
               sci.crypt       0.91      0.92      0.91       396
         sci.electronics       0.75      0.69      0.72       393
                 sci.med       0.89      0.83      0.86       396
               sci.space       0.86      0.91      0.88       394
  soc.religion.christian       0.87      0.92      0.89       398
      talk.politics.guns       0.72      0.90      0.80       364
   talk.politics.mideast       0.96      0.84      0.90       376
      talk.politics.misc       0.77      0.59      0.67       310
      talk.religion.misc       0.68      0.60      0.63       251

                accuracy                           0.83      7532
               macro avg       0.82      0.82      0.82      7532
            weighted avg       0.83      0.83      0.83      7532

confusion matrix:
[[236   1   0   1   1   0   2   0   2   2   1   1   1   8  11  17   0   2
    1  32]
 [  3 302  12  10   9  13   4   1   3   3   1   6  10   1   7   1   1   0
    2   0]
 [  0  20 302  28  11  10   2   1   4   0   2   2   5   1   2   2   1   0
    0   1]
 [  0  11  29 300  17   2  12   2   0   0   0   3  15   0   0   0   0   0
    1   0]
 [  0   5   3  30 323   0   8   0   1   0   0   0   9   2   0   0   3   0
    0   1]
 [  0  40  36   4   5 295   2   2   0   0   1   0   3   0   5   1   0   0
    1   0]
 [  0   1   1  10   9   0 338   6   4   1   1   1   9   2   3   2   1   0
    0   1]
 [  0   4   1   2   3   1   8 345   8   2   0   0  16   1   0   1   2   0
    2   0]
 [  1   1   0   1   2   0   3  10 373   1   0   0   1   2   0   1   1   0
    1   0]
 [  0   2   0   0   0   1   4   3   0 365  11   2   1   3   2   0   1   2
    0   0]
 [  0   0   0   0   4   0   4   0   0   8 382   0   0   0   0   0   0   0
    1   0]
 [  0   4   3   3   1   0   4   4   0   0   0 363   5   0   1   1   3   0
    4   0]
 [  2   5   6  36  16   2   4  13   7   3   3   8 272   5   5   3   0   0
    1   2]
 [  1   9   1   9   2   1   6   1   1   6   0   3   6 329   4   3   1   1
    7   5]
 [  1   8   0   1   2   3   2   1   2   2   0   2   3   4 360   1   1   0
    1   0]
 [  7   0   1   0   0   0   1   1   0   0   0   0   2   1   3 366   0   2
    2  12]
 [  0   2   1   1   0   0   2   4   0   0   0   3   0   3   1   0 326   3
   11   7]
 [ 11   1   0   1   1   3   0   2   3   4   1   1   3   0   6   3   3 316
   12   5]
 [  2   2   0   1   1   0   1   0   1   2   0   3   1   4   7   1  92   3
  183   6]
 [ 38   0   4   0   0   0   1   1   0   1   0   0   3   3   3  20  18   1
    8 150]]

================================================================================
SGD Classifier (penalty = L2)
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,
              random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 1.969s
test time:  0.036s
accuracy:   0.859
dimensionality: 129791
density: 0.317326

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.82      0.78      0.80       319
           comp.graphics       0.76      0.82      0.79       389
 comp.os.ms-windows.misc       0.78      0.76      0.77       394
comp.sys.ibm.pc.hardware       0.74      0.77      0.75       392
   comp.sys.mac.hardware       0.83      0.86      0.85       385
          comp.windows.x       0.90      0.78      0.84       395
            misc.forsale       0.84      0.90      0.87       390
               rec.autos       0.93      0.91      0.92       396
         rec.motorcycles       0.96      0.96      0.96       398
      rec.sport.baseball       0.92      0.95      0.93       397
        rec.sport.hockey       0.95      0.98      0.97       399
               sci.crypt       0.93      0.95      0.94       396
         sci.electronics       0.82      0.75      0.78       393
                 sci.med       0.91      0.89      0.90       396
               sci.space       0.89      0.94      0.91       394
  soc.religion.christian       0.85      0.94      0.89       398
      talk.politics.guns       0.74      0.94      0.83       364
   talk.politics.mideast       0.97      0.92      0.95       376
      talk.politics.misc       0.87      0.60      0.71       310
      talk.religion.misc       0.76      0.61      0.68       251

                accuracy                           0.86      7532
               macro avg       0.86      0.85      0.85      7532
            weighted avg       0.86      0.86      0.86      7532

confusion matrix:
[[248   1   0   3   0   0   1   0   2   0   0   2   1   7   8  24   0   1
    0  21]
 [  2 318  13   7   5  17   3   1   1   2   1   4   6   0   5   1   1   0
    0   2]
 [  0  18 301  33  11  11   2   1   0   4   1   2   1   1   4   0   0   0
    0   4]
 [  0  12  23 300  20   1  10   3   0   2   0   0  19   0   0   0   1   0
    0   1]
 [  0   5   4  15 332   1  12   1   0   2   0   0   9   0   1   0   2   0
    1   0]
 [  1  34  32   3   2 310   3   0   1   0   1   1   1   2   3   0   1   0
    0   0]
 [  0   3   1   8   9   0 350   6   2   1   0   1   6   2   0   0   0   0
    1   0]
 [  0   1   1   4   1   0  10 359   6   1   0   1   8   1   0   0   1   0
    2   0]
 [  0   0   0   1   0   0   3   6 383   1   0   0   0   1   1   0   1   0
    0   1]
 [  0   0   1   0   0   0   3   2   0 378  12   0   0   0   0   0   0   0
    1   0]
 [  0   0   0   0   1   0   0   0   0   5 393   0   0   0   0   0   0   0
    0   0]
 [  0   2   1   0   2   1   3   2   0   2   0 378   2   0   0   1   1   1
    0   0]
 [  1   7   7  29  11   1   3   5   3   2   1  10 295   6   6   2   1   1
    1   1]
 [  2   4   0   2   2   2   6   1   1   3   2   0   5 354   2   3   2   2
    1   2]
 [  1   8   0   0   1   0   2   0   0   0   1   1   4   4 370   0   1   0
    1   0]
 [  4   0   2   1   0   0   0   0   0   1   0   0   2   3   3 373   0   0
    0   9]
 [  0   1   1   1   0   0   2   0   0   1   0   2   0   1   1   0 342   1
    9   2]
 [  6   1   0   0   0   2   0   1   0   4   1   0   0   1   1   5   2 347
    5   0]
 [  4   1   0   0   1   0   2   0   0   0   0   3   0   3   6   2  95   2
  186   5]
 [ 35   2   1   1   0   0   1   0   0   3   0   0   0   2   5  26  13   1
    7 154]]

================================================================================
SGD Classifier (penalty = L1)
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,
              random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 1.947s
test time:  0.041s
accuracy:   0.860
dimensionality: 129791
density: 0.319993

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.82      0.78      0.80       319
           comp.graphics       0.76      0.82      0.79       389
 comp.os.ms-windows.misc       0.77      0.77      0.77       394
comp.sys.ibm.pc.hardware       0.75      0.76      0.75       392
   comp.sys.mac.hardware       0.85      0.86      0.85       385
          comp.windows.x       0.88      0.79      0.83       395
            misc.forsale       0.84      0.90      0.87       390
               rec.autos       0.92      0.91      0.91       396
         rec.motorcycles       0.96      0.96      0.96       398
      rec.sport.baseball       0.91      0.95      0.93       397
        rec.sport.hockey       0.95      0.98      0.97       399
               sci.crypt       0.92      0.95      0.94       396
         sci.electronics       0.83      0.77      0.80       393
                 sci.med       0.91      0.89      0.90       396
               sci.space       0.89      0.94      0.92       394
  soc.religion.christian       0.86      0.94      0.90       398
      talk.politics.guns       0.73      0.93      0.82       364
   talk.politics.mideast       0.98      0.92      0.95       376
      talk.politics.misc       0.87      0.60      0.71       310
      talk.religion.misc       0.75      0.61      0.68       251

                accuracy                           0.86      7532
               macro avg       0.86      0.85      0.85      7532
            weighted avg       0.86      0.86      0.86      7532

confusion matrix:
[[248   1   0   3   0   0   1   0   2   0   0   2   1   8   8  22   0   1
    0  22]
 [  1 319  12   7   5  18   3   1   1   3   1   5   6   0   4   1   0   0
    0   2]
 [  0  21 303  28   9  12   1   1   0   4   1   2   1   1   4   0   0   0
    1   5]
 [  0  11  26 298  18   1  11   3   0   2   0   0  18   0   2   0   1   0
    0   1]
 [  0   5   5  14 331   1  13   1   0   2   0   1   9   1   0   0   2   0
    0   0]
 [  1  35  32   2   2 312   3   0   0   0   1   1   0   1   4   0   1   0
    0   0]
 [  0   2   1   8   8   0 352   6   2   1   0   1   6   2   0   0   0   0
    1   0]
 [  0   1   1   4   1   0  10 359   7   1   0   1   7   1   0   0   1   0
    2   0]
 [  0   0   0   1   0   0   3   7 382   1   0   0   0   1   1   0   1   0
    0   1]
 [  0   0   1   0   0   0   3   2   0 378  12   0   1   0   0   0   0   0
    0   0]
 [  0   0   0   0   0   1   0   0   0   6 392   0   0   0   0   0   0   0
    0   0]
 [  0   2   1   0   2   1   3   2   0   2   0 378   2   0   0   1   1   1
    0   0]
 [  0   6   5  29  11   2   3   5   3   1   0  11 301   6   5   1   1   1
    1   1]
 [  1   5   0   2   2   2   5   1   1   4   2   0   6 352   2   3   2   2
    2   2]
 [  1   7   0   0   1   0   2   0   0   0   1   1   4   5 370   0   1   0
    1   0]
 [  4   0   2   1   0   0   0   0   0   1   0   0   2   2   3 374   0   0
    0   9]
 [  0   1   1   1   0   0   2   1   0   1   0   3   0   1   1   0 339   1
    9   3]
 [  7   2   0   0   0   2   0   1   0   4   1   0   0   1   1   5   2 345
    5   0]
 [  3   1   0   0   1   1   2   0   0   0   1   4   0   3   5   1  95   1
  187   5]
 [ 36   1   1   0   0   0   2   1   0   3   0   0   0   1   4  27  15   1
    5 154]]

================================================================================
Ada Boost Classifier
________________________________________________________________________________
Training: 
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=None)
train time: 13.417s
test time:  0.642s
accuracy:   0.508
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.70      0.29      0.41       319
           comp.graphics       0.58      0.30      0.39       389
 comp.os.ms-windows.misc       0.63      0.52      0.57       394
comp.sys.ibm.pc.hardware       0.63      0.15      0.24       392
   comp.sys.mac.hardware       0.62      0.54      0.57       385
          comp.windows.x       0.75      0.47      0.58       395
            misc.forsale       0.84      0.66      0.74       390
               rec.autos       0.79      0.54      0.64       396
         rec.motorcycles       0.86      0.76      0.80       398
      rec.sport.baseball       0.67      0.54      0.60       397
        rec.sport.hockey       0.91      0.63      0.74       399
               sci.crypt       0.83      0.75      0.79       396
         sci.electronics       0.11      0.73      0.20       393
                 sci.med       0.00      0.00      0.00       396
               sci.space       0.76      0.58      0.66       394
  soc.religion.christian       0.60      0.76      0.67       398
      talk.politics.guns       0.60      0.67      0.64       364
   talk.politics.mideast       0.92      0.56      0.70       376
      talk.politics.misc       0.46      0.35      0.40       310
      talk.religion.misc       0.35      0.21      0.26       251

                accuracy                           0.51      7532
               macro avg       0.63      0.50      0.53      7532
            weighted avg       0.64      0.51      0.54      7532

confusion matrix:
[[ 92   0   0   0  15   2   3   0   1   2   1   0  82   0   6  70   5   0
    5  35]
 [  0 115  14   2  11  23   2   1   0   0   0   4 205   1   8   1   1   1
    0   0]
 [  0  23 203   8  28  19   0   6   0   1   0   6  92   0   4   1   0   1
    1   1]
 [  0  20  44  57  10   1   3   1   0   0   0   8 235   0   9   1   2   0
    1   0]
 [  2   7   1   4 207   3   5   0   0   2   2   4 140   0   4   0   0   0
    1   3]
 [  0  11  45   0   6 184   1   3   0   0   0   4 128   2   6   0   0   0
    5   0]
 [  0   4   3   4   6   0 256   6   3   3   0   2  90   0   5   2   2   0
    4   0]
 [  0   0   1   0   0   0   6 215  16   0   0   1 131   0   2   2  13   2
    6   1]
 [  0   0   0   0   1   1   6  13 301   1   0   2  65   0   2   1   4   0
    1   0]
 [  0   5   0   0   1   0   3   2   2 216  22   2 136   0   1   2   1   0
    2   2]
 [  0   1   0   0   6   0   6   0   0  76 250   0  49   0   2   1   2   0
    2   4]
 [  0   0   2   4   2   0   2   0   3   0   0 296  53   0   4   1  11   0
   18   0]
 [  0   8   6   7  11   3   4  17  15   6   0  18 287   0   6   3   1   0
    1   0]
 [  1   1   0   0   3   5   4   2   0   1   0   0 348   0   0  16   2   5
    6   2]
 [  0   1   0   0  16   0   2   2   3   9   0   3 116   0 229   4   1   0
    8   0]
 [  9   1   0   0   0   1   0   0   0   0   0   0  58   0   2 301   0   3
    3  20]
 [  0   0   0   3   0   2   3   3   7   1   0   4  45   0   4   2 245   1
   36   8]
 [ 21   0   0   0   0   0   0   0   0   4   0   0  88   0   4  11   3 211
   17  17]
 [  1   2   1   0   0   1   0   1   1   0   0   1  80   0   0  11  95   4
  108   4]
 [  5   0   0   1  13   0   0   1   0   2   0   0  73   0   4  72  18   2
    8  52]]

================================================================================
Random forest
________________________________________________________________________________
Training: 
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False)
train time: 55.904s
test time:  1.000s
accuracy:   0.788
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.74      0.69      0.71       319
           comp.graphics       0.64      0.74      0.69       389
 comp.os.ms-windows.misc       0.68      0.79      0.73       394
comp.sys.ibm.pc.hardware       0.66      0.67      0.67       392
   comp.sys.mac.hardware       0.78      0.78      0.78       385
          comp.windows.x       0.80      0.73      0.76       395
            misc.forsale       0.77      0.89      0.83       390
               rec.autos       0.85      0.85      0.85       396
         rec.motorcycles       0.92      0.90      0.91       398
      rec.sport.baseball       0.86      0.90      0.88       397
        rec.sport.hockey       0.90      0.93      0.91       399
               sci.crypt       0.90      0.93      0.92       396
         sci.electronics       0.74      0.57      0.64       393
                 sci.med       0.85      0.77      0.80       396
               sci.space       0.82      0.90      0.86       394
  soc.religion.christian       0.73      0.93      0.82       398
      talk.politics.guns       0.67      0.88      0.76       364
   talk.politics.mideast       0.94      0.80      0.87       376
      talk.politics.misc       0.81      0.50      0.62       310
      talk.religion.misc       0.79      0.37      0.50       251

                accuracy                           0.79      7532
               macro avg       0.79      0.78      0.78      7532
            weighted avg       0.79      0.79      0.78      7532

confusion matrix:
[[219   2   1   2   4   1   4   1   0   2   1   1   0   8   3  43   6   4
    0  17]
 [  1 288  23  12   8  24   4   2   2   3   0   5   4   0   8   1   2   2
    0   0]
 [  0  22 313  21   9   9   0   1   1   1   0   2   4   1   6   0   0   3
    1   0]
 [  1  23  34 263  21   4  14   3   0   3   1   1  18   1   4   0   0   0
    1   0]
 [  0   8  13  30 302   2  12   2   1   2   0   0   8   1   3   0   0   0
    1   0]
 [  0  33  47  10   2 289   4   0   0   0   0   2   1   0   6   0   0   1
    0   0]
 [  0   3   1  11   8   2 348   2   0   3   1   1   4   1   4   0   1   0
    0   0]
 [  1   4   3   2   1   1  13 335  16   0   2   0   4   6   2   0   5   0
    1   0]
 [  0   1   0   2   2   1   9  13 360   1   0   1   2   2   0   1   3   0
    0   0]
 [  0   4   0   1   1   0   3   1   1 357  22   3   1   1   0   1   0   0
    0   1]
 [  0   1   0   0   3   0   3   0   0  15 370   0   1   0   2   2   0   0
    2   0]
 [  0   2   3   2   2   1   4   3   0   1   0 368   5   0   1   0   4   0
    0   0]
 [  1  20  15  30  16   7  10  16   7   7   4  14 225   4  12   3   1   0
    0   1]
 [  3  14   2   5   4   8   9   6   0   7   1   0  20 303   3   6   2   1
    2   0]
 [  0   9   0   2   2   3   3   1   1   2   1   1   2   6 356   0   1   0
    4   0]
 [  5   1   1   1   0   2   2   0   0   1   0   0   3   2   2 372   0   1
    2   3]
 [  0   6   0   0   1   0   3   3   1   4   1   4   3   3   3   2 319   1
   10   0]
 [ 28   0   0   3   0   6   1   4   0   3   4   2   0   2   1   6   7 302
    6   1]
 [  3   2   1   1   1   1   3   0   1   1   2   3   1   8  12   3 106   4
  156   1]
 [ 35   5   1   0   0   0   1   2   0   3   3   0   0   8   6  69  18   2
    6  92]]

================================================================================
SGDClassifier Elastic-Net penalty
________________________________________________________________________________
Training: 
SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,
              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',
              power_t=0.5, random_state=None, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
train time: 4.305s
test time:  0.036s
accuracy:   0.850
dimensionality: 129791
density: 0.029241

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.79      0.77      0.78       319
           comp.graphics       0.76      0.78      0.77       389
 comp.os.ms-windows.misc       0.74      0.78      0.76       394
comp.sys.ibm.pc.hardware       0.75      0.73      0.74       392
   comp.sys.mac.hardware       0.83      0.86      0.85       385
          comp.windows.x       0.89      0.77      0.82       395
            misc.forsale       0.85      0.90      0.88       390
               rec.autos       0.90      0.89      0.90       396
         rec.motorcycles       0.95      0.95      0.95       398
      rec.sport.baseball       0.91      0.95      0.93       397
        rec.sport.hockey       0.94      0.97      0.96       399
               sci.crypt       0.92      0.95      0.94       396
         sci.electronics       0.80      0.75      0.77       393
                 sci.med       0.89      0.90      0.90       396
               sci.space       0.89      0.94      0.91       394
  soc.religion.christian       0.85      0.94      0.89       398
      talk.politics.guns       0.72      0.91      0.80       364
   talk.politics.mideast       0.96      0.91      0.93       376
      talk.politics.misc       0.85      0.59      0.70       310
      talk.religion.misc       0.79      0.57      0.67       251

                accuracy                           0.85      7532
               macro avg       0.85      0.84      0.84      7532
            weighted avg       0.85      0.85      0.85      7532

confusion matrix:
[[246   1   0   1   0   0   2   0   1   2   0   3   2  10   9  24   0   1
    0  17]
 [  1 302  15   8   7  19   3   2   2   3   2   5   7   0   6   2   0   3
    1   1]
 [  0  17 308  26  11   7   1   1   0   7   1   3   0   1   4   1   0   0
    0   6]
 [  0   8  33 287  17   3  10   5   0   0   0   1  25   0   1   0   0   0
    0   2]
 [  0   4   5  20 333   1   9   0   0   1   0   0   9   1   0   0   2   0
    0   0]
 [  1  35  36   4   4 303   2   0   1   0   1   0   1   2   4   0   1   0
    0   0]
 [  0   2   2   6   8   0 352   5   2   1   1   1   8   2   0   0   0   0
    0   0]
 [  0   1   1   3   2   0   9 354   7   1   0   0  13   0   0   0   3   0
    2   0]
 [  0   0   0   0   1   0   3   8 380   1   0   0   1   2   0   0   0   0
    1   1]
 [  0   0   0   0   0   0   4   2   0 377  12   0   0   1   0   0   0   1
    0   0]
 [  0   1   0   0   1   0   2   0   0   6 389   0   0   0   0   0   0   0
    0   0]
 [  0   2   2   0   2   1   1   3   0   1   0 378   1   0   0   1   3   0
    1   0]
 [  0   3   9  26  10   2   4   6   4   3   1  11 295   6   8   2   1   2
    0   0]
 [  2   4   0   0   3   2   4   1   1   3   3   0   4 356   2   2   3   2
    3   1]
 [  0   9   0   0   1   0   2   1   0   0   0   1   2   6 370   0   1   0
    1   0]
 [  8   0   2   1   0   0   0   0   0   1   0   0   2   2   3 373   0   0
    0   6]
 [  0   1   2   1   0   0   1   3   0   3   0   5   0   2   0   0 332   1
   10   3]
 [  8   3   1   0   1   4   0   1   0   3   1   0   0   1   2   3   2 341
    5   0]
 [  3   1   0   0   1   0   3   1   1   0   1   3   0   4   5   1  98   4
  183   1]
 [ 41   1   1   0   0   0   2   0   0   3   0   0   0   2   4  29  15   1
    8 144]]

================================================================================
NearestCentroid (aka Rocchio classifier)
________________________________________________________________________________
Training: 
NearestCentroid(metric='euclidean', shrink_threshold=None)
train time: 0.048s
test time:  0.044s
accuracy:   0.787
classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.82      0.58      0.68       319
           comp.graphics       0.58      0.81      0.67       389
 comp.os.ms-windows.misc       0.75      0.77      0.76       394
comp.sys.ibm.pc.hardware       0.73      0.70      0.71       392
   comp.sys.mac.hardware       0.83      0.81      0.82       385
          comp.windows.x       0.85      0.72      0.78       395
            misc.forsale       0.80      0.86      0.83       390
               rec.autos       0.86      0.87      0.87       396
         rec.motorcycles       0.97      0.91      0.94       398
      rec.sport.baseball       0.95      0.91      0.93       397
        rec.sport.hockey       0.96      0.92      0.94       399
               sci.crypt       0.97      0.77      0.86       396
         sci.electronics       0.44      0.78      0.56       393
                 sci.med       0.93      0.63      0.75       396
               sci.space       0.88      0.85      0.86       394
  soc.religion.christian       0.79      0.90      0.84       398
      talk.politics.guns       0.74      0.84      0.79       364
   talk.politics.mideast       0.98      0.80      0.88       376
      talk.politics.misc       0.69      0.60      0.64       310
      talk.religion.misc       0.65      0.55      0.60       251

                accuracy                           0.79      7532
               macro avg       0.81      0.78      0.79      7532
            weighted avg       0.81      0.79      0.79      7532

confusion matrix:
[[184   9   0   0   1   0   1   4   2   0   0   1  15   8   1  46   1   2
    4  40]
 [  1 314  11   6  10  17   4   0   0   0   0   0  17   0   6   0   0   0
    0   3]
 [  0  29 304  25   6   7   1   2   0   0   0   0  11   0   3   0   0   0
    2   4]
 [  0  24  23 274   9   2   9   3   0   0   0   0  44   0   4   0   0   0
    0   0]
 [  0   7   8  23 312   1  11   0   0   2   0   0  18   0   2   0   0   0
    1   0]
 [  0  47  42   6   1 285   3   0   0   0   0   0   8   0   3   0   0   0
    0   0]
 [  0   5   2  18   7   0 335   6   1   0   0   0  16   0   0   0   0   0
    0   0]
 [  1   6   0   0   0   1   9 345   2   0   0   0  26   0   3   0   0   0
    2   1]
 [  0   2   0   0   1   0   6  13 362   0   0   0  12   0   0   0   0   0
    2   0]
 [  0   4   0   0   2   0   6   2   1 360  13   0   8   0   0   0   0   0
    1   0]
 [  0   3   0   0   8   0   3   0   0  10 366   0   7   0   2   0   0   0
    0   0]
 [  0  15   2   0   3   2   0   0   1   0   0 306  46   1   3   0   5   0
   12   0]
 [  1  21  11  24   8   2   5   5   1   0   0   3 306   1   4   0   0   0
    1   0]
 [  3  24   0   0   2   3  11   7   2   0   0   0  75 251   2   6   0   1
    7   2]
 [  0  15   0   0   2   2   3   2   0   1   0   0  24   2 334   0   0   0
    9   0]
 [  2   5   1   0   0   1   1   0   0   1   0   0  14   0   2 357   0   0
    3  11]
 [  0   1   0   1   1   0   4   6   0   3   0   4  16   2   1   0 306   1
   12   6]
 [  7   5   0   0   0  11   1   3   1   2   1   0  14   1   0   3   4 301
   19   3]
 [  0   3   0   0   1   0   2   3   1   0   0   1  11   0   7   1  87   0
  187   6]
 [ 25   6   1   0   1   0   2   0   0   0   0   0   8   4   3  39  12   1
   10 139]]

================================================================================
Naive Bayes
________________________________________________________________________________
Training: 
MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)
train time: 0.181s
test time:  0.043s
accuracy:   0.837
dimensionality: 129791
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.83      0.80      0.81       319
           comp.graphics       0.68      0.74      0.71       389
 comp.os.ms-windows.misc       0.77      0.59      0.67       394
comp.sys.ibm.pc.hardware       0.66      0.77      0.71       392
   comp.sys.mac.hardware       0.83      0.84      0.84       385
          comp.windows.x       0.82      0.79      0.81       395
            misc.forsale       0.81      0.79      0.80       390
               rec.autos       0.90      0.91      0.91       396
         rec.motorcycles       0.94      0.96      0.95       398
      rec.sport.baseball       0.96      0.94      0.95       397
        rec.sport.hockey       0.95      0.98      0.96       399
               sci.crypt       0.87      0.93      0.90       396
         sci.electronics       0.79      0.77      0.78       393
                 sci.med       0.90      0.84      0.87       396
               sci.space       0.87      0.92      0.89       394
  soc.religion.christian       0.85      0.94      0.90       398
      talk.politics.guns       0.76      0.91      0.83       364
   talk.politics.mideast       0.97      0.94      0.96       376
      talk.politics.misc       0.77      0.63      0.69       310
      talk.religion.misc       0.77      0.63      0.69       251

                accuracy                           0.84      7532
               macro avg       0.84      0.83      0.83      7532
            weighted avg       0.84      0.84      0.84      7532

confusion matrix:
[[254   0   0   3   0   1   0   0   1   1   0   1   0   5   4  23   2   3
    3  18]
 [  0 289  12  14   8  25   9   0   0   1   0   7  14   0   7   1   0   1
    0   1]
 [  1  31 232  55   8  27   9   0   0   1   1   7   5   3   4   4   0   0
    4   2]
 [  0   9  21 300  20   3  11   2   0   1   0   2  21   0   2   0   0   0
    0   0]
 [  0   6   7  12 323   2   9   4   0   2   1   4  11   2   1   0   0   0
    1   0]
 [  0  45  11  10   4 312   2   1   1   0   0   3   1   1   3   0   1   0
    0   0]
 [  0   4   5  25  11   0 310  11   7   0   3   0   8   3   2   0   1   0
    0   0]
 [  0   1   1   4   0   0  12 361   6   0   0   0   6   1   1   0   1   0
    2   0]
 [  0   0   0   1   1   0   2   7 384   0   0   0   3   0   0   0   0   0
    0   0]
 [  0   0   0   0   1   0   4   1   2 372  12   0   0   0   3   1   1   0
    0   0]
 [  0   0   0   0   0   0   0   0   1   3 391   1   0   1   0   1   1   0
    0   0]
 [  1   4   1   2   2   1   3   3   0   0   0 370   1   3   2   0   3   0
    0   0]
 [  1  10   7  24   6   2   8   3   2   0   0  13 301   8   6   0   0   1
    1   0]
 [  2  12   0   2   1   2   5   3   0   3   0   3   6 331   4   6   2   2
   10   2]
 [  0   7   0   4   1   3   0   1   1   0   0   1   3   4 361   1   1   0
    6   0]
 [  3   2   1   1   0   0   0   0   0   1   2   0   0   2   2 376   0   0
    2   6]
 [  0   0   0   0   0   0   1   0   2   1   0   5   1   2   1   0 333   0
   12   6]
 [  4   1   0   0   0   1   0   0   0   0   1   0   0   0   0   1   2 354
   11   1]
 [  6   1   0   0   1   0   0   2   0   0   1   5   0   1   9   2  75   2
  195  10]
 [ 34   1   2   0   0   0   0   1   0   0   0   1   0   2   5  26  14   1
    6 158]]

________________________________________________________________________________
Training: 
BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)
train time: 0.171s
test time:  0.174s
accuracy:   0.771
dimensionality: 129791
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.75      0.83      0.79       319
           comp.graphics       0.55      0.74      0.63       389
 comp.os.ms-windows.misc       0.79      0.07      0.13       394
comp.sys.ibm.pc.hardware       0.51      0.76      0.61       392
   comp.sys.mac.hardware       0.66      0.83      0.74       385
          comp.windows.x       0.80      0.71      0.75       395
            misc.forsale       0.56      0.88      0.68       390
               rec.autos       0.87      0.87      0.87       396
         rec.motorcycles       0.90      0.94      0.92       398
      rec.sport.baseball       0.96      0.90      0.93       397
        rec.sport.hockey       0.97      0.92      0.95       399
               sci.crypt       0.88      0.85      0.86       396
         sci.electronics       0.70      0.73      0.72       393
                 sci.med       0.91      0.71      0.80       396
               sci.space       0.87      0.83      0.85       394
  soc.religion.christian       0.90      0.89      0.90       398
      talk.politics.guns       0.83      0.84      0.83       364
   talk.politics.mideast       0.98      0.83      0.90       376
      talk.politics.misc       0.74      0.59      0.66       310
      talk.religion.misc       0.69      0.63      0.66       251

                accuracy                           0.77      7532
               macro avg       0.79      0.77      0.76      7532
            weighted avg       0.80      0.77      0.76      7532

confusion matrix:
[[265   1   0   3   1   0   3   0   2   1   0   1   1   2   1  14   1   2
    1  20]
 [  1 287   0  18  14  20  19   0   0   0   0   8  10   0   9   0   0   1
    1   1]
 [  1  73  27 163  35  33  22   2   2   1   0  11  11   2   4   1   1   0
    4   1]
 [  0   9   3 297  28   4  20   0   0   0   0   2  28   0   1   0   0   0
    0   0]
 [  0   6   1  14 321   1  20   1   0   0   0   1  13   1   5   0   0   0
    1   0]
 [  0  70   2  12   9 279  15   0   1   0   0   3   4   0   0   0   0   0
    0   0]
 [  0   5   0  22   8   1 342   5   0   0   0   0   4   2   0   0   1   0
    0   0]
 [  0   1   0   2   1   0  27 346   8   0   0   1   6   1   0   0   0   0
    3   0]
 [  0   1   0   0   2   0   7  10 374   0   0   0   2   0   0   0   0   0
    2   0]
 [  1   0   0   2   2   0  12   1   1 358  11   0   2   2   2   0   0   0
    3   0]
 [  1   1   1   0   4   0  10   0   3   7 368   1   1   0   0   0   0   0
    2   0]
 [  1  10   0   8  12   3  11   2   0   0   0 336   5   2   3   0   2   0
    1   0]
 [  1  16   0  27  11   1  23   3   2   0   0  14 288   4   3   0   0   0
    0   0]
 [  3  14   0   4  15   1  25   8  10   1   0   0  18 282   4   2   2   1
    6   0]
 [  3  14   0   3   4   3  18   3   0   0   0   0  10   4 326   0   0   0
    6   0]
 [  4   4   0   4   4   0   8   0   2   1   0   0   2   1   1 356   0   0
    1  10]
 [  2   1   0   0   4   1  10   4   3   0   0   3   3   3   0   0 304   0
   15  11]
 [ 21   2   0   4   5   0   9   0   1   2   0   0   0   1   0   4   1 311
   13   2]
 [  9   4   0   0   3   1   5   6   5   2   0   2   3   1  10   0  51   0
  182  26]
 [ 39   4   0   2   0   0   6   6   0   0   0   0   0   1   5  19   5   1
    4 159]]

________________________________________________________________________________
Training: 
ComplementNB(alpha=0.1, class_prior=None, fit_prior=True, norm=False)
train time: 0.194s
test time:  0.045s
accuracy:   0.838
dimensionality: 129791
density: 1.000000

classification report:
                          precision    recall  f1-score   support

             alt.atheism       0.80      0.79      0.79       319
           comp.graphics       0.77      0.73      0.75       389
 comp.os.ms-windows.misc       0.79      0.63      0.70       394
comp.sys.ibm.pc.hardware       0.69      0.75      0.72       392
   comp.sys.mac.hardware       0.87      0.83      0.85       385
          comp.windows.x       0.81      0.86      0.83       395
            misc.forsale       0.85      0.71      0.78       390
               rec.autos       0.89      0.91      0.90       396
         rec.motorcycles       0.91      0.98      0.94       398
      rec.sport.baseball       0.90      0.96      0.93       397
        rec.sport.hockey       0.91      0.99      0.95       399
               sci.crypt       0.88      0.97      0.92       396
         sci.electronics       0.79      0.71      0.75       393
                 sci.med       0.86      0.86      0.86       396
               sci.space       0.86      0.93      0.89       394
  soc.religion.christian       0.82      0.94      0.87       398
      talk.politics.guns       0.75      0.90      0.82       364
   talk.politics.mideast       0.93      0.96      0.95       376
      talk.politics.misc       0.86      0.63      0.73       310
      talk.religion.misc       0.80      0.56      0.66       251

                accuracy                           0.84      7532
               macro avg       0.84      0.83      0.83      7532
            weighted avg       0.84      0.84      0.83      7532

confusion matrix:
[[251   0   0   3   1   0   0   0   1   1   0   2   0   7   4  30   2   5
    2  10]
 [  1 284  14   9   9  25   5   3   1   4   3   9  10   1   5   1   1   2
    0   2]
 [  1  20 249  42   4  30   5   4   3   4   2   7   1   6   6   4   0   0
    5   1]
 [  4  10  18 295   9   4  10   2   3   0   0   3  19   2   7   1   3   0
    1   1]
 [  0   3   4  10 319   5   7   7   3   3   1   2  12   2   2   1   2   0
    1   1]
 [  0  23   9   2   3 339   3   0   1   1   4   4   2   1   3   0   0   0
    0   0]
 [  0   2   9  32  10   2 278  13   7   4   6   0  10   7   3   3   3   1
    0   0]
 [  0   3   1   6   3   0   4 360   6   0   0   1   6   1   1   0   3   0
    1   0]
 [  0   0   0   0   0   1   1   3 389   1   0   0   3   0   0   0   0   0
    0   0]
 [  0   0   0   0   0   0   1   0   2 380  10   0   1   0   1   1   0   1
    0   0]
 [  0   0   0   0   0   0   0   0   0   3 396   0   0   0   0   0   0   0
    0   0]
 [  0   0   0   0   2   1   1   1   0   2   1 383   0   2   1   0   2   0
    0   0]
 [  5   9   6  17   4   3   5   6   9   3   3  15 280  11  10   2   2   2
    0   1]
 [  1   5   3   4   0   2   4   1   0   5   2   1   9 342   1   5   2   4
    4   1]
 [  0   5   0   2   1   4   0   2   0   0   0   1   2   4 367   0   2   2
    2   0]
 [  4   1   1   1   0   0   0   0   1   2   1   0   0   4   2 374   1   0
    0   6]
 [  1   1   0   1   0   3   1   0   1   2   0   5   0   4   3   0 328   2
   10   2]
 [  2   2   0   1   2   0   0   0   0   2   2   0   0   0   0   2   0 362
    1   0]
 [  6   1   1   0   1   1   1   1   0   2   2   3   0   2   6   1  70   6
  196  10]
 [ 39   0   2   0   0   0   1   2   0   5   0   0   0   3   5  32  15   2
    5 140]]

================================================================================
LinearSVC with L1-based feature selection

Process finished with exit code 0
